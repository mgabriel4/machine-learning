{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#machine-learning","title":"\ud83e\udde0 Machine Learning","text":"<p>Bem-vindo(a) \u00e0 documenta\u00e7\u00e3o da mat\u00e9ria Machine Learning, desenvolvida durante o 4\u00b0 semestre do curso de Ci\u00eancia de Dados e Neg\u00f3cios da ESPM!</p> <p>Este espa\u00e7o re\u00fane projetos, exerc\u00edcios, anota\u00e7\u00f5es e estudos pr\u00e1ticos realizados ao longo da disciplina \u2014 explorando desde o pr\u00e9-processamento de dados at\u00e9 a implementa\u00e7\u00e3o de modelos supervisionados e n\u00e3o supervisionados. O objetivo \u00e9 consolidar o aprendizado e servir como um reposit\u00f3rio de refer\u00eancia para futuras aplica\u00e7\u00f5es em ci\u00eancia de dados, estat\u00edstica aplicada e modelagem preditiva.</p>"},{"location":"#conteudos-principais","title":"\ud83d\ude80 Conte\u00fados Principais","text":"<ul> <li>An\u00e1lise Explorat\u00f3ria de Dados (EDA) \u2014 limpeza, tratamento de nulos, detec\u00e7\u00e3o de outliers e visualiza\u00e7\u00f5es.</li> <li>Modelos Supervisionados \u2014 regress\u00e3o linear, \u00e1rvore de decis\u00e3o e KNN.</li> <li>Modelos N\u00e3o Supervisionados \u2014 clustering com K-Means e an\u00e1lise de agrupamentos.</li> <li>M\u00e9tricas de Avalia\u00e7\u00e3o \u2014 acur\u00e1cia, matriz de confus\u00e3o, R\u00b2, p-valor e interpreta\u00e7\u00e3o de resultados.</li> <li>Documenta\u00e7\u00e3o e Visualiza\u00e7\u00e3o \u2014 gr\u00e1ficos interativos, diagramas com Mermaid e dashboards.</li> </ul>"},{"location":"#datasets-utilizados","title":"\ud83d\udcca Datasets Utilizados","text":"<p>Os experimentos apresentados nesta documenta\u00e7\u00e3o foram desenvolvidos com diferentes bases de dados p\u00fablicas:</p> <ul> <li>\ud83c\udfe0 Ames Housing Dataset (Kaggle)   \u2014 Previs\u00e3o do pre\u00e7o de im\u00f3veis com vari\u00e1veis categ\u00f3ricas e num\u00e9ricas.</li> </ul>"},{"location":"#tecnologias-e-ferramentas","title":"\ud83e\udde9 Tecnologias e Ferramentas","text":"<ul> <li>Linguagens: Python (pandas, scikit-learn, matplotlib, seaborn)</li> <li>Ambiente: Jupyter Notebook / VS Code  </li> <li>Documenta\u00e7\u00e3o: MkDocs + Material Theme  </li> <li>Visualiza\u00e7\u00e3o: Mermaid, Google Charts, Tableau</li> </ul>"},{"location":"#referencias","title":"\ud83d\udcda Refer\u00eancias","text":"<ul> <li>Material for MkDocs</li> <li>Mermaid Live Editor</li> <li>Documenta\u00e7\u00e3o oficial do scikit-learn</li> <li>Kaggle Datasets</li> </ul> <p>Documenta\u00e7\u00e3o constru\u00edda com MkDocs Material.</p>"},{"location":"classes/arvore-de-decisao/classificacao/","title":"Projeto 1","text":""},{"location":"classes/arvore-de-decisao/classificacao/#projeto-baixa-media-e-alta-renda-qual-casa-voce-pode-comprar-nos-eua","title":"Projeto: Baixa, m\u00e9dia e alta renda, qual casa voc\u00ea pode comprar nos EUA?","text":""},{"location":"classes/arvore-de-decisao/classificacao/#objetivo","title":"Objetivo","text":"<p>O objetivo deste projeto \u00e9 utilizar um modelo de \u00e1rvore de decis\u00e3o para classificar im\u00f3veis em diferentes faixas de pre\u00e7o (baixa, m\u00e9dia e alta renda) com base em suas caracter\u00edsticas.</p>"},{"location":"classes/arvore-de-decisao/classificacao/#1-exploracao-dos-dados-eda","title":"1. Explora\u00e7\u00e3o dos Dados (EDA)","text":"<p>Nesta etapa, foi realizada a an\u00e1lise explorat\u00f3ria do dataset AmesHousing.csv, verificando as primeiras linhas, informa\u00e7\u00f5es gerais, estat\u00edsticas descritivas, valores ausentes e visualiza\u00e7\u00e3o de algumas vari\u00e1veis categ\u00f3ricas.</p> OutputCodeExplica\u00e7\u00e3o <pre><code>Primeiras 5 linhas do dataset:\n    Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area  ... Misc Val Mo Sold Yr Sold Sale Type Sale Condition SalePrice\n0      1  526301100           20        RL         141.0     31770  ...        0       5    2010       WD          Normal    215000\n1      2  526350040           20        RH          80.0     11622  ...        0       6    2010       WD          Normal    105000\n2      3  526351010           20        RL          81.0     14267  ...    12500       6    2010       WD          Normal    172000\n3      4  526353030           20        RL          93.0     11160  ...        0       4    2010       WD          Normal    244000\n4      5  527105010           60        RL          74.0     13830  ...        0       3    2010       WD          Normal    189900\n\n[5 rows x 82 columns]\n\nInforma\u00e7\u00f5es do dataset:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2930 entries, 0 to 2929\nData columns (total 82 columns):\n#   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n0   Order            2930 non-null   int64  \n1   PID              2930 non-null   int64  \n2   MS SubClass      2930 non-null   int64  \n3   MS Zoning        2930 non-null   object \n4   Lot Frontage     2440 non-null   float64\n5   Lot Area         2930 non-null   int64  \n6   Street           2930 non-null   object \n7   Alley            198 non-null    object \n8   Lot Shape        2930 non-null   object \n9   Land Contour     2930 non-null   object \n10  Utilities        2930 non-null   object \n11  Lot Config       2930 non-null   object \n12  Land Slope       2930 non-null   object \n13  Neighborhood     2930 non-null   object \n14  Condition 1      2930 non-null   object \n15  Condition 2      2930 non-null   object \n16  Bldg Type        2930 non-null   object \n17  House Style      2930 non-null   object \n18  Overall Qual     2930 non-null   int64  \n19  Overall Cond     2930 non-null   int64  \n20  Year Built       2930 non-null   int64  \n21  Year Remod/Add   2930 non-null   int64  \n22  Roof Style       2930 non-null   object \n23  Roof Matl        2930 non-null   object \n24  Exterior 1st     2930 non-null   object \n25  Exterior 2nd     2930 non-null   object \n26  Mas Vnr Type     1155 non-null   object \n27  Mas Vnr Area     2907 non-null   float64\n28  Exter Qual       2930 non-null   object \n29  Exter Cond       2930 non-null   object \n30  Foundation       2930 non-null   object \n31  Bsmt Qual        2850 non-null   object \n32  Bsmt Cond        2850 non-null   object \n33  Bsmt Exposure    2847 non-null   object \n34  BsmtFin Type 1   2850 non-null   object \n35  BsmtFin SF 1     2929 non-null   float64\n36  BsmtFin Type 2   2849 non-null   object \n37  BsmtFin SF 2     2929 non-null   float64\n38  Bsmt Unf SF      2929 non-null   float64\n39  Total Bsmt SF    2929 non-null   float64\n40  Heating          2930 non-null   object \n41  Heating QC       2930 non-null   object \n42  Central Air      2930 non-null   object \n43  Electrical       2929 non-null   object \n44  1st Flr SF       2930 non-null   int64  \n45  2nd Flr SF       2930 non-null   int64  \n46  Low Qual Fin SF  2930 non-null   int64  \n47  Gr Liv Area      2930 non-null   int64  \n48  Bsmt Full Bath   2928 non-null   float64\n49  Bsmt Half Bath   2928 non-null   float64\n50  Full Bath        2930 non-null   int64  \n51  Half Bath        2930 non-null   int64  \n52  Bedroom AbvGr    2930 non-null   int64  \n53  Kitchen AbvGr    2930 non-null   int64  \n54  Kitchen Qual     2930 non-null   object \n55  TotRms AbvGrd    2930 non-null   int64  \n56  Functional       2930 non-null   object \n57  Fireplaces       2930 non-null   int64  \n58  Fireplace Qu     1508 non-null   object \n59  Garage Type      2773 non-null   object \n60  Garage Yr Blt    2771 non-null   float64\n61  Garage Finish    2771 non-null   object \n62  Garage Cars      2929 non-null   float64\n63  Garage Area      2929 non-null   float64\n64  Garage Qual      2771 non-null   object \n65  Garage Cond      2771 non-null   object \n66  Paved Drive      2930 non-null   object \n67  Wood Deck SF     2930 non-null   int64  \n68  Open Porch SF    2930 non-null   int64  \n69  Enclosed Porch   2930 non-null   int64  \n70  3Ssn Porch       2930 non-null   int64  \n71  Screen Porch     2930 non-null   int64  \n72  Pool Area        2930 non-null   int64  \n73  Pool QC          13 non-null     object \n74  Fence            572 non-null    object \n75  Misc Feature     106 non-null    object \n76  Misc Val         2930 non-null   int64  \n77  Mo Sold          2930 non-null   int64  \n78  Yr Sold          2930 non-null   int64  \n79  Sale Type        2930 non-null   object \n80  Sale Condition   2930 non-null   object \n81  SalePrice        2930 non-null   int64  \ndtypes: float64(11), int64(28), object(43)\nmemory usage: 1.8+ MB\nNone\n\nEstat\u00edsticas descritivas:\n            Order           PID  MS SubClass MS Zoning  Lot Frontage  ...      Mo Sold      Yr Sold Sale Type Sale Condition      SalePrice\ncount   2930.00000  2.930000e+03  2930.000000      2930   2440.000000  ...  2930.000000  2930.000000      2930           2930    2930.000000\nunique         NaN           NaN          NaN         7           NaN  ...          NaN          NaN        10              6            NaN\ntop            NaN           NaN          NaN        RL           NaN  ...          NaN          NaN       WD          Normal            NaN\nfreq           NaN           NaN          NaN      2273           NaN  ...          NaN          NaN      2536           2413            NaN\nmean    1465.50000  7.144645e+08    57.387372       NaN     69.224590  ...     6.216041  2007.790444       NaN            NaN  180796.060068\nstd      845.96247  1.887308e+08    42.638025       NaN     23.365335  ...     2.714492     1.316613       NaN            NaN   79886.692357\nmin        1.00000  5.263011e+08    20.000000       NaN     21.000000  ...     1.000000  2006.000000       NaN            NaN   12789.000000\n25%      733.25000  5.284770e+08    20.000000       NaN     58.000000  ...     4.000000  2007.000000       NaN            NaN  129500.000000\n50%     1465.50000  5.354536e+08    50.000000       NaN     68.000000  ...     6.000000  2008.000000       NaN            NaN  160000.000000\n75%     2197.75000  9.071811e+08    70.000000       NaN     80.000000  ...     8.000000  2009.000000       NaN            NaN  213500.000000\nmax     2930.00000  1.007100e+09   190.000000       NaN    313.000000  ...    12.000000  2010.000000       NaN            NaN  755000.000000\n\n[11 rows x 82 columns]\n\nValores ausentes por coluna:\nOrder               0\nPID                 0\nMS SubClass         0\nMS Zoning           0\nLot Frontage      490\n                ... \nMo Sold             0\nYr Sold             0\nSale Type           0\nSale Condition      0\nSalePrice           0\nLength: 82, dtype: int64\n</code></pre> <pre><code>from matplotlib import patches\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n\ndf = pd.read_csv('data/AmesHousing.csv')\n\nprint(\"Primeiras 5 linhas do dataset:\")\nprint(df.head())\n\nprint(\"\\nInforma\u00e7\u00f5es do dataset:\")\nprint(df.info())\n\nprint(\"\\nEstat\u00edsticas descritivas:\")\nprint(df.describe(include='all'))\n\ncolunas = df.columns\nprint(\"\\nColunas do dataset:\")\nprint(colunas)\n\nnulos = df.isnull().sum()\nprint(\"\\nValores ausentes por coluna:\")\nprint(nulos.head(100).to_string())\n\nplt.style.use('ggplot')\n\nplt.figure(figsize=(15,10))\ndf.isnull().mean().sort_values(ascending=False).head(20).plot(kind='bar', color='salmon')\nplt.title(\"Percentual de Valores Ausentes nas 20 Vari\u00e1veis com Mais NAs\")\nplt.ylabel(\"% de valores faltantes\")\nplt.savefig('./docs/classes/arvore-de-decisao/img/valores_ausentes.png')\n\n#vari\u00e1veis categ\u00f3ricas\nplt.figure(figsize=(25, 20))\nplt.subplot(2, 2, 1)\nsns.countplot(data=df, x='MS Zoning', palette='viridis', order=df['MS Zoning'].value_counts().index)\nplt.title('Classifica\u00e7\u00e3o de Zonas Residenciais')\nplt.xticks(rotation=45)\nplt.xlabel('Zona de Zoneamento')\nplt.ylabel('Contagem')\nplt.tight_layout()\n\nplt.subplot(2, 2, 2)\ndf['Street'].value_counts().plot.pie(autopct='%1.1f%%', figsize=(6,6), colors=sns.color_palette('viridis', 5), labels=df['Street'].value_counts().index)\nplt.title('Tipo de Rua')\nplt.ylabel('')  #remove o label do eixo Y\nplt.tight_layout()\n\nplt.subplot(2, 2, 3)\ndf['Neighborhood'].value_counts().head(5).plot(kind='bar', color=sns.color_palette('viridis', 5))\nplt.title('Top 5 Vizinhan\u00e7as')\nplt.xticks(rotation=45)\nplt.xlabel('Vizinhan\u00e7a')\nplt.ylabel('Contagem')\nplt.tight_layout()\n\nplt.subplot(2, 2, 4)\nsns.countplot(data=df, x='House Style', palette='viridis', order=df['House Style'].value_counts().index)\nplt.xticks(rotation=45)\nplt.title('Estilo da Casa')\nplt.ylabel('Contagem')\nplt.tight_layout()\nplt.savefig('./docs/classes/arvore-de-decisao/img/categoricas.png')\n\n#vari\u00e1veis num\u00e9ricas\nplt.figure(figsize=(15, 10))\nplt.subplot(2, 2, 1)\nsns.histplot(df['SalePrice'], bins=30, kde=True, color='salmon')\nplt.title(\"Distribui\u00e7\u00e3o do Pre\u00e7o de Venda\")\nplt.xlabel(\"Pre\u00e7o de Venda\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.tight_layout()\n\nplt.subplot(2, 2, 2)\nsns.histplot(df['Gr Liv Area'], bins=30, kde=True, color='salmon')\nplt.title(\"Distribui\u00e7\u00e3o da \u00c1rea Acima do Solo\")\nplt.xlabel(\"\u00c1rea Acima do Solo (p\u00e9s\u00b2)\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.tight_layout()\n\nplt.subplot(2, 2, 3)\nsns.histplot(df['Year Built'], bins=30, kde=True, color='salmon')\nplt.title(\"Distribui\u00e7\u00e3o do Ano de Constru\u00e7\u00e3o\")\nplt.xlabel(\"Ano de Constru\u00e7\u00e3o\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.tight_layout()\n\nplt.subplot(2, 2, 4)\nsns.histplot(df['Total Bsmt SF'], bins=30, kde=True, color='salmon')\nplt.title(\"Distribui\u00e7\u00e3o da \u00c1rea do Por\u00e3o\")\nplt.xlabel(\"\u00c1rea do Por\u00e3o (p\u00e9s\u00b2)\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.tight_layout()\nplt.savefig('./docs/classes/arvore-de-decisao/img/dist_geral_numericas.png')\nplt.show()  \n\nplt.figure(figsize=(15, 10))\nplt.subplot(2, 1, 1)\nsns.boxplot(x='Neighborhood', y='SalePrice', palette='viridis', data=df)\nplt.title(\"Pre\u00e7o por Bairro\")\nplt.xticks(rotation=90)\n\nplt.subplot(2, 1, 2)\nsns.boxplot(x='Overall Qual', y='SalePrice', data=df, palette='viridis')\nplt.title(\"Qualidade Geral vs Pre\u00e7o de Venda\")\n\nplt.tight_layout()\nplt.savefig('./docs/classes/arvore-de-decisao/img/boxplots.png')\n\ncorr_cols = ['Lot Area', 'Gr Liv Area', 'Total Bsmt SF', 'Garage Area', '1st Flr SF',\n    '2nd Flr SF', 'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'TotRms AbvGrd',\n    'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add']\nplt.figure(figsize=(10,8))\nsns.heatmap(df[corr_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title(\"Correla\u00e7\u00e3o entre vari\u00e1veis num\u00e9ricas\")\nplt.savefig('./docs/classes/arvore-de-decisao/img/matriz_correlacao.png')</code></pre> <p>Utilizamos a biblioteca Pandas para a an\u00e1lise de dados e a biblioteca Matplotlib.pyplot para fazer os gr\u00e1ficos para uma melhor visualiza\u00e7\u00e3o dos dados.</p> <p>Logo ap\u00f3s carregarmos a base de dados:</p> <ul> <li>base = pd.read_csv('caminho/para/a/base')</li> </ul> <p>Utilizamos comandos para a an\u00e1lise explorat\u00f3ria da base:</p> <ul> <li> <p>base.head() -&gt; sem a especifica\u00e7\u00e3o de quantas linhas puxar, o head imprime as primeiras 5 linhas da sua base de dados.</p> </li> <li> <p>base.info() -&gt; mostra as colunas da base de dados e seus respectivos tipos.</p> </li> <li> <p>base.describe(include='all') -&gt; imprime as estat\u00edsticas descritivas das colunas da base de dados, como a frequ\u00eancia, a m\u00e9dia, o desvio padr\u00e3o e etc.</p> </li> <li> <p>base.isnull().sum() -&gt; soma todos os valores nulos por coluna.</p> </li> </ul> <p>Ap\u00f3s finalizar esse processo com a an\u00e1lise explorat\u00f3ria, precisamos fazer a visualiza\u00e7\u00e3o da an\u00e1lise realizada. Por isso, utilizamos os seguintes comandos:</p> <ul> <li> <p>plt.style.use('ggplot') -&gt; sendo plt a biblioteca do matplotlib, esse comando serve para escolhermos o estilo que </p> </li> <li> <p>plt.figure(figsize=(15, 10)) -&gt; cria uma nova figura para colocar os gr\u00e1ficos.</p> </li> <li> <p>plt.subplot(2, 2, 1) -&gt; este comando divide a figura em uma grade de 2 linhas por 2 colunas. O \u00faltimo par\u00e2metro \u00e9 a posi\u00e7\u00e3o do gr\u00e1fico.</p> </li> <li> <p>base['nome_coluna'].value_counts().plot.pie(autopct='%1.1f%%', figsize=(6,6)) -&gt; constr\u00f3i um gr\u00e1fico de pizza com a coluna escolhida da base. O comando autopct exibe as porcentagens em cada fatia.</p> </li> <li> <p>plt.title('T\u00edtulo') -&gt; intitula o gr\u00e1fico.</p> </li> <li> <p>plt.ylabel('') -&gt; remove o label do eixo Y, comando utilizado apenas em gr\u00e1ficos de pizza</p> </li> <li> <p>base['nome_coluna'].value_counts().head(5).plot(kind='bar') -&gt; constr\u00f3i um gr\u00e1fico de barra, e com o comando head(5) ir\u00e1 aparecer apenas os 5 mais frequentes daquela coluna.</p> </li> <li> <p>plt.xticks(rotation=45) -&gt; rotaciona o gr\u00e1fico de barra a 45\u00b0 para uma melhor visualiza\u00e7\u00e3o.</p> </li> <li> <p>plt.savefig('caminho/que/deseja/salvar') -&gt; salva a figura completa que foi iniciada l\u00e1 no in\u00edcio do c\u00f3digo no caminho que foi apontado.</p> </li> <li> <p>plt.show() -&gt; exibe a figura na tela.</p> </li> </ul>"},{"location":"classes/arvore-de-decisao/classificacao/#graficos-gerados-na-analise-exploratoria","title":"Gr\u00e1ficos gerados na an\u00e1lise explorat\u00f3ria","text":"<p>A partir deste gr\u00e1fico, podemos observar que algumas vari\u00e1veis possuem uma quantidade significativa de valores ausentes. Isso pode impactar a an\u00e1lise e o desempenho do modelo, sendo necess\u00e1rio considerar estrat\u00e9gias para lidar com esses dados faltantes, como imputa\u00e7\u00e3o ou remo\u00e7\u00e3o dessas vari\u00e1veis.</p> <p></p> <p>No gr\u00e1fico acima, podemos observar a distribui\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas selecionadas. Isso nos ajuda a entender a frequ\u00eancia de diferentes categorias dentro dessas vari\u00e1veis, o que pode ser \u00fatil para identificar padr\u00f5es ou tend\u00eancias no conjunto de dados. Um exemplo disso \u00e9 o gr\u00e1fico de pizza que mostra a predomin\u00e2ncia de um tipo espec\u00edfico de rua, indicando que a maioria das propriedades est\u00e1 localizada em ruas pavimentadas. E o gr\u00e1fico de classe de zona residencial, onde a maioria das propriedades est\u00e1 situada em zonas residenciais (RL: Residential Low Density).</p> <p></p> <p>No gr\u00e1fico acima, podemos observar a distribui\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas selecionadas. Isso nos ajuda a entender a frequ\u00eancia de diferentes valores dentro dessas vari\u00e1veis, o que pode ser \u00fatil para identificar padr\u00f5es ou tend\u00eancias no conjunto de dados. Um exemplo disso \u00e9 a distribui\u00e7\u00e3o do pre\u00e7o de venda, que apresenta uma assimetria \u00e0 direita, indicando que a maioria das propriedades tem pre\u00e7os mais baixos, com algumas propriedades de alto valor.</p> <p></p> <p>Os boxplots acima ilustram a rela\u00e7\u00e3o entre a qualidade geral das casas e o pre\u00e7o de venda. Podemos observar que, em geral, casas com melhor qualidade tendem a ter pre\u00e7os de venda mais altos. No entanto, tamb\u00e9m h\u00e1 uma varia\u00e7\u00e3o significativa nos pre\u00e7os dentro de cada categoria de qualidade, indicando que outros fatores al\u00e9m da qualidade geral tamb\u00e9m influenciam o pre\u00e7o de venda. Al\u00e9m disso, temos um boxplot sobre o pre\u00e7o de venda e o bairro onde a casa est\u00e1 localizada. Podemos observar que certos bairros, como NoRidge e NridgHt, apresentam pre\u00e7os de venda significativamente mais altos em compara\u00e7\u00e3o com outros bairros. Isso sugere que a localiza\u00e7\u00e3o \u00e9 um fator importante na determina\u00e7\u00e3o do valor das propriedades.</p> <p></p> <p>A matriz de correla\u00e7\u00e3o acima mostra a rela\u00e7\u00e3o entre v\u00e1rias vari\u00e1veis num\u00e9ricas no conjunto de dados. Podemos observar que algumas vari\u00e1veis, como \"Gr Liv Area\" (\u00e1rea de vida acima do solo) e \"Overall Qual\" (qualidade geral), t\u00eam uma correla\u00e7\u00e3o positiva forte com o pre\u00e7o de venda (\"SalePrice\"). Isso indica que casas com maior \u00e1rea de vida e melhor qualidade tendem a ter pre\u00e7os de venda mais altos. Outras vari\u00e1veis, como \"Lot Area\" (\u00e1rea do lote) e \"Garage Area\" (\u00e1rea da garagem), tamb\u00e9m mostram correla\u00e7\u00f5es positivas, mas em menor grau. Essas informa\u00e7\u00f5es podem ser \u00fateis para identificar quais caracter\u00edsticas das casas s\u00e3o mais influentes na determina\u00e7\u00e3o do pre\u00e7o de venda.</p>"},{"location":"classes/arvore-de-decisao/classificacao/#2-pre-processamento","title":"2. Pr\u00e9-processamento","text":"<p>Como primeira fase do pr\u00e9-processamento, precisamos tratar os valores ausentes. Como visto anteriormente, principalmente no gr\u00e1fico gerado, temos muitos valores nulos a serem tratados. Abaixo est\u00e3o listados a quantidade dos valores nulos em todas as vari\u00e1veis:</p> <ul> <li>Lot Frontage (490 valores nulos),</li> <li>Mas Vnr Type (1775 valores nulos),</li> <li>Mas Vnr Area (23 valores nulos),</li> <li>Bsmt Qual (80 valores nulos),</li> <li>Bsmt Cond (80 valores nulos),</li> <li>Bsmt Exposure (83 valores nulos),</li> <li>BsmtFin Type 1 (80 valores nulos),</li> <li>BsmtFin SF 1 (1 valor nulo),</li> <li>BsmtFin Type 2 (81 valores nulos),</li> <li>BsmtFin SF 2 (1 valor nulo),</li> <li>Bsmt Unf SF (1 valor nulo),</li> <li>Total Bsmt SF (1 valor nulo),</li> <li>Electrical (1 valor nulo),</li> <li>Bsmt Full Bath (2 valores nulos),</li> <li>Bsmt Half Bath (2 valores nulos),</li> <li>Fireplace Qu (1422 valores nulos),</li> <li>Garage Type (157 valores nulos),</li> <li>Garage Yr Blt (159 valores nulos),</li> <li>Garage Finish (159 valores nulos),</li> <li>Garage Cars (1 valor nulo),</li> <li>Garage Area (1 valor nulo),</li> <li>Garage Qual (159 valores nulos),</li> <li>Garage Cond (159 valores nulos),</li> <li>Pool QC (2917 valores nulos),</li> <li>Fence (2358 valores nulos),</li> <li>Misc Feature (2824 valores nulos).</li> </ul> <p>Para tratar esses valores nulos, utilizei as seguintes estrat\u00e9gias:</p> <ul> <li>Remo\u00e7\u00e3o das vari\u00e1veis com muitos valores nulos (mais de 50% dos dados ausentes): Mas Vnr Type, Fireplace Qu, Pool QC, Fence e Misc Feature.</li> <li>Preenchimento dos valores nulos em vari\u00e1veis num\u00e9ricas com a mediana da coluna.</li> <li>Preenchimento dos valores nulos em vari\u00e1veis categ\u00f3ricas com a moda da coluna.</li> </ul> CodeOutput <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\ndf = pd.read_csv('data/AmesHousing.csv')\n\n#tratamento de valores nulos\nmaiores_valores_nulos = ['Pool QC', 'Misc Feature', 'Alley', 'Fence', 'Fireplace Qu']\ndf = df.drop(columns=maiores_valores_nulos)\n\n# Preenchimento de valores nulos em vari\u00e1veis num\u00e9ricas com a mediana\nnum_cols = df.select_dtypes(include=['float64', 'int64']).columns\nfor col in num_cols:\n    df[col].fillna(df[col].median(), inplace=True)\n\n# Preenchimento de valores nulos em vari\u00e1veis categ\u00f3ricas com a moda\ncat_cols = df.select_dtypes(include=['object']).columns\nfor col in cat_cols:\n    df[col].fillna(df[col].mode()[0], inplace=True)\n\nnulos = df.isnull().sum()\nprint(\"\\nValores ausentes por coluna:\")\nprint(nulos.head(100).to_string())  # Verificando se ainda h\u00e1 valores nulos</code></pre> <pre><code>Valores ausentes por coluna:\n    Order              0\n    PID                0\n    MS SubClass        0\n    MS Zoning          0\n    Lot Frontage       0\n    Lot Area           0\n    Street             0\n    Lot Shape          0\n    Land Contour       0\n    Utilities          0\n    Lot Config         0\n    Land Slope         0\n    Neighborhood       0\n    Condition 1        0\n    Condition 2        0\n    Bldg Type          0\n    House Style        0\n    Overall Qual       0\n    Overall Cond       0\n    Year Built         0\n    Year Remod/Add     0\n    Roof Style         0\n    Roof Matl          0\n    Exterior 1st       0\n    Exterior 2nd       0\n    Mas Vnr Type       0\n    Mas Vnr Area       0\n    Exter Qual         0\n    Exter Cond         0\n    Foundation         0\n    Bsmt Qual          0\n    Bsmt Cond          0\n    Bsmt Exposure      0\n    BsmtFin Type 1     0\n    BsmtFin SF 1       0\n    BsmtFin Type 2     0\n    BsmtFin SF 2       0\n    Bsmt Unf SF        0\n    Total Bsmt SF      0\n    Heating            0\n    Heating QC         0\n    Central Air        0\n    Electrical         0\n    1st Flr SF         0\n    2nd Flr SF         0\n    Low Qual Fin SF    0\n    Gr Liv Area        0\n    Bsmt Full Bath     0\n    Bsmt Half Bath     0\n    Full Bath          0\n    Half Bath          0\n    Bedroom AbvGr      0\n    Kitchen AbvGr      0\n    Kitchen Qual       0\n    TotRms AbvGrd      0\n    Functional         0\n    Fireplaces         0\n    Garage Type        0\n    Garage Yr Blt      0\n    Garage Finish      0\n    Garage Cars        0\n    Garage Area        0\n    Garage Qual        0\n    Garage Cond        0\n    Paved Drive        0\n    Wood Deck SF       0\n    Open Porch SF      0\n    Enclosed Porch     0\n    3Ssn Porch         0\n    Screen Porch       0\n    Pool Area          0\n    Misc Val           0\n    Mo Sold            0\n    Yr Sold            0\n    Sale Type          0\n    Sale Condition     0\n    SalePrice          0\n</code></pre> <p>Ap\u00f3s tratar os valores nulos, precisamos transformar as vari\u00e1veis categ\u00f3ricas em num\u00e9ricas para que o modelo de \u00e1rvore de decis\u00e3o possa utiliz\u00e1-las. Utilizei duas t\u00e9cnicas principais para isso:</p> <p>Label Encoding -&gt; serve para vari\u00e1veis categ\u00f3ricas que possuem uma ordem ou hierarquia e que t\u00eam um n\u00famero limitado de categorias. Exemplo: Poor, Fair, Average, Good, Excellent.</p> <p>One-Hot Encoding -&gt; serve para vari\u00e1veis categ\u00f3ricas que n\u00e3o possuem uma ordem ou hierarquia e t\u00eam um n\u00famero elevado de categorias. Exemplo: Cor do carro (vermelho, azul, verde).</p> <p>Mapeamento Manual -&gt; para vari\u00e1veis ordinais espec\u00edficas, onde atribu\u00edmos valores num\u00e9ricos com base na ordem percebida.</p> <p>Na tabela abaixo est\u00e3o listadas as vari\u00e1veis que foram transformadas utilizando cada t\u00e9cnica:</p> T\u00e9cnica Vari\u00e1veis Mapeamento Manual Exter Qual, Exter Cond, Bsmt Qual, Bsmt Cond, Heating QC, Kitchen Qual, Garage Qual, Garage Cond, Bsmt Exposure, BsmtFin Type 1, BsmtFin Type 2, Functional One-Hot Encoding MS Zoning, Street, Lot Shape, Land Contour, Utilities, Lot Config, Land Slope, Neighborhood, Condition 1, Condition 2, Bldg Type, House Style, Roof Style, Roof Matl, Exterior 1st, Exterior 2nd, Mas Vnr Type, Foundation, Heating, Central Air, Electrical, Garage Type, Garage Finish, Paved Drive, Sale Type, Sale Condition <ul> <li>Vari\u00e1veis categ\u00f3ricas foram transformadas em num\u00e9ricas para uso no modelo.</li> </ul> OutputCode <pre><code>    MS SubClass  Lot Frontage  ...  Sale Condition_Normal  Sale Condition_Partial\n0           20         141.0  ...                   True                   False\n1           20          80.0  ...                   True                   False\n2           20          81.0  ...                   True                   False\n3           20          93.0  ...                   True                   False\n4           60          74.0  ...                   True                   False\n5           60          78.0  ...                   True                   False\n6          120          41.0  ...                   True                   False\n7          120          43.0  ...                   True                   False\n8          120          39.0  ...                   True                   False\n9           60          60.0  ...                   True                   False\n\n[10 rows x 233 columns]\n</code></pre> <pre><code>variaveis_ordinal = {\n    'Exter Qual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n    'Exter Cond': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n    'Bsmt Qual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n    'Bsmt Cond': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n    'Heating QC': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n    'Kitchen Qual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n    'Garage Qual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n    'Garage Cond': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n    'Bsmt Exposure': {'No':1, 'Mn':2, 'Av':3, 'Gd':4},\n    'BsmtFin Type 1': {'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6},\n    'BsmtFin Type 2': {'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6},\n    'Functional': {'Sal':1, 'Sev':2, 'Maj2':3, 'Maj1':4, 'Mod':5, 'Min2':6, 'Min1':7, 'Typ':8},\n}\n\nfor col, mapping in variaveis_ordinal.items():\n    if col in df.columns:\n        df[col] = df[col].map(mapping).fillna(0).astype(int)\n\nvariaveis_nominais = [\n    'MS Zoning', 'Street', 'Lot Shape', 'Land Contour',\n    'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood', 'Condition 1',\n    'Condition 2', 'Bldg Type', 'House Style', 'Roof Style', 'Roof Matl',\n    'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation',\n    'Heating', 'Central Air', 'Electrical', 'Garage Type', 'Garage Finish',\n    'Paved Drive', 'Sale Type', 'Sale Condition'\n]\n\ndf = pd.get_dummies(df, columns=variaveis_nominais, drop_first=False)\nprint(df.head(10))\n</code></pre>"},{"location":"classes/arvore-de-decisao/classificacao/#3-divisao-dos-dados","title":"3. Divis\u00e3o dos Dados","text":"<p>Nessa etapa, eu criei a vari\u00e1vel target e escolhi como features todas as outras vari\u00e1veis para a constru\u00e7\u00e3o do meu modelo. Os dados foram divididos em conjuntos de treino e teste, utilizando 70% dos dados para treino e 30% para teste. \u00c9 importante garantir que a divis\u00e3o seja feita de forma aleat\u00f3ria para evitar vi\u00e9s.</p> OutputCodeExplica\u00e7\u00e3o <pre><code>    Target\n0    981\n1    980\n2    969\nName: count, dtype: int64\nFeatures usadas no modelo:\n['MS SubClass', 'Lot Frontage', 'Lot Area', 'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add', 'Mas Vnr Area', 'Exter Qual', 'Exter Cond', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin SF 1', 'BsmtFin Type 2', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', 'Heating QC', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'Kitchen Qual', 'TotRms AbvGrd', 'Functional', 'Fireplaces', 'Garage Yr Blt', 'Garage Cars', 'Garage Area', 'Garage Qual', 'Garage Cond', 'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch', 'Screen Porch', 'Pool Area', 'Misc Val', 'Mo Sold', 'Yr Sold', 'MS Zoning_A (agr)', 'MS Zoning_C (all)', 'MS Zoning_FV', 'MS Zoning_I (all)', 'MS Zoning_RH', 'MS Zoning_RL', 'MS Zoning_RM', 'Street_Grvl', 'Street_Pave', 'Lot Shape_IR1', 'Lot Shape_IR2', 'Lot Shape_IR3', 'Lot Shape_Reg', 'Land Contour_Bnk', 'Land Contour_HLS', 'Land Contour_Low', 'Land Contour_Lvl', 'Utilities_AllPub', 'Utilities_NoSeWa', 'Utilities_NoSewr', 'Lot Config_Corner', 'Lot Config_CulDSac', 'Lot Config_FR2', 'Lot Config_FR3', 'Lot Config_Inside', 'Land Slope_Gtl', 'Land Slope_Mod', 'Land Slope_Sev', 'Neighborhood_Blmngtn', 'Neighborhood_Blueste', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_ClearCr', 'Neighborhood_CollgCr', 'Neighborhood_Crawfor', 'Neighborhood_Edwards', 'Neighborhood_Gilbert', 'Neighborhood_Greens', 'Neighborhood_GrnHill', 'Neighborhood_IDOTRR', 'Neighborhood_Landmrk', 'Neighborhood_MeadowV', 'Neighborhood_Mitchel', 'Neighborhood_NAmes', 'Neighborhood_NPkVill', 'Neighborhood_NWAmes', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown', 'Neighborhood_SWISU', 'Neighborhood_Sawyer', 'Neighborhood_SawyerW', 'Neighborhood_Somerst', 'Neighborhood_StoneBr', 'Neighborhood_Timber', 'Neighborhood_Veenker', 'Condition 1_Artery', 'Condition 1_Feedr', 'Condition 1_Norm', 'Condition 1_PosA', 'Condition 1_PosN', 'Condition 1_RRAe', 'Condition 1_RRAn', 'Condition 1_RRNe', 'Condition 1_RRNn', 'Condition 2_Artery', 'Condition 2_Feedr', 'Condition 2_Norm', 'Condition 2_PosA', 'Condition 2_PosN', 'Condition 2_RRAe', 'Condition 2_RRAn', 'Condition 2_RRNn', 'Bldg Type_1Fam', 'Bldg Type_2fmCon', 'Bldg Type_Duplex', 'Bldg Type_Twnhs', 'Bldg Type_TwnhsE', 'House Style_1.5Fin', 'House Style_1.5Unf', 'House Style_1Story', 'House Style_2.5Fin', 'House Style_2.5Unf', 'House Style_2Story', 'House Style_SFoyer', 'House Style_SLvl', 'Roof Style_Flat', 'Roof Style_Gable', 'Roof Style_Gambrel', 'Roof Style_Hip', 'Roof Style_Mansard', 'Roof Style_Shed', 'Roof Matl_ClyTile', 'Roof Matl_CompShg', 'Roof Matl_Membran', 'Roof Matl_Metal', 'Roof Matl_Roll', 'Roof Matl_Tar&amp;Grv', 'Roof Matl_WdShake', 'Roof Matl_WdShngl', 'Exterior 1st_AsbShng', 'Exterior 1st_AsphShn', 'Exterior 1st_BrkComm', 'Exterior 1st_BrkFace', 'Exterior 1st_CBlock', 'Exterior 1st_CemntBd', 'Exterior 1st_HdBoard', 'Exterior 1st_ImStucc', 'Exterior 1st_MetalSd', 'Exterior 1st_Plywood', 'Exterior 1st_PreCast', 'Exterior 1st_Stone', 'Exterior 1st_Stucco', 'Exterior 1st_VinylSd', 'Exterior 1st_Wd Sdng', 'Exterior 1st_WdShing', 'Exterior 2nd_AsbShng', 'Exterior 2nd_AsphShn', 'Exterior 2nd_Brk Cmn', 'Exterior 2nd_BrkFace', 'Exterior 2nd_CBlock', 'Exterior 2nd_CmentBd', 'Exterior 2nd_HdBoard', 'Exterior 2nd_ImStucc', 'Exterior 2nd_MetalSd', 'Exterior 2nd_Other', 'Exterior 2nd_Plywood', 'Exterior 2nd_PreCast', 'Exterior 2nd_Stone', 'Exterior 2nd_Stucco', 'Exterior 2nd_VinylSd', 'Exterior 2nd_Wd Sdng', 'Exterior 2nd_Wd Shng', 'Mas Vnr Type_BrkCmn', 'Mas Vnr Type_BrkFace', 'Mas Vnr Type_CBlock', 'Mas Vnr Type_Stone', 'Foundation_BrkTil', 'Foundation_CBlock', 'Foundation_PConc', 'Foundation_Slab', 'Foundation_Stone', 'Foundation_Wood', 'Heating_Floor', 'Heating_GasA', 'Heating_GasW', 'Heating_Grav', 'Heating_OthW', 'Heating_Wall', 'Central Air_N', 'Central Air_Y', 'Electrical_FuseA', 'Electrical_FuseF', 'Electrical_FuseP', 'Electrical_Mix', 'Electrical_SBrkr', 'Garage Type_2Types', 'Garage Type_Attchd', 'Garage Type_Basment', 'Garage Type_BuiltIn', 'Garage Type_CarPort', 'Garage Type_Detchd', 'Garage Finish_Fin', 'Garage Finish_RFn', 'Garage Finish_Unf', 'Paved Drive_N', 'Paved Drive_P', 'Paved Drive_Y', 'Sale Type_COD', 'Sale Type_CWD', 'Sale Type_Con', 'Sale Type_ConLD', 'Sale Type_ConLI', 'Sale Type_ConLw', 'Sale Type_New', 'Sale Type_Oth', 'Sale Type_VWD', 'Sale Type_WD ', 'Sale Condition_Abnorml', 'Sale Condition_AdjLand', 'Sale Condition_Alloca', 'Sale Condition_Family', 'Sale Condition_Normal', 'Sale Condition_Partial']\nTamanho do treino: (2051, 232)\nTamanho do teste: (879, 232)\n\nDistribui\u00e7\u00e3o das classes no target:\nTarget\n1    0.344222\n0    0.338859\n2    0.316919\nName: proportion, dtype: float64\n</code></pre> <pre><code>#criando a target para classificar o pre\u00e7o das casas em baixa, m\u00e9dia e alta\nprint(df['SalePrice'].describe()) \n\ndf['Target'] = pd.qcut( \n    df['SalePrice'], \n    q=3, \n    labels=['Baixa', 'M\u00e9dia', 'Alta']\n)\n\ndf['Target'] = df['Target'].map({'Baixa':0, 'M\u00e9dia':1, 'Alta':2}).astype('int')\n\nprint(df['Target'].value_counts()) \n\nx = df.drop(columns=['SalePrice', 'Target'])\ny = df['Target']\n\nfeatures = x.columns.tolist()\nprint(\"Features usadas no modelo:\\n\", features)\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n\nprint(\"Tamanho do treino:\", X_train.shape)\nprint(\"Tamanho do teste:\", X_test.shape)\nprint(\"\\nDistribui\u00e7\u00e3o das classes no target:\")\nprint(y_train.value_counts(normalize=True))</code></pre> <ul> <li> <p>As vari\u00e1veis de entrada (features -&gt; vari\u00e1veis x) e sa\u00edda (target -&gt; vari\u00e1vel y) foram definidas.</p> </li> <li> <p>Split 70/30 para treino e teste, garantindo avalia\u00e7\u00e3o justa do modelo.</p> </li> </ul>"},{"location":"classes/arvore-de-decisao/classificacao/#4-treinamento-do-modelo","title":"4. Treinamento do Modelo","text":"<p>O modelo de \u00e1rvore de decis\u00e3o foi treinado com os dados de treino.</p> CodeExplica\u00e7\u00e3o <pre><code>#cria\u00e7\u00e3o e treino do modelo de \u00e1rvore de decis\u00e3o\nclf = DecisionTreeClassifier(random_state=42, max_depth=3, criterion='entropy')  # voc\u00ea pode ajustar max_depth\nclf.fit(X_train, y_train)</code></pre> <ul> <li> <p>Como crit\u00e9rio de divis\u00e3o, utilizou-se a entropia para medir a incerteza com base na teoria da informa\u00e7\u00e3o (usado quando se quer interpretar a \u00e1rvore em termos de bits de informa\u00e7\u00e3o).</p> </li> <li> <p>Utilizou-se o <code>DecisionTreeClassifier</code> com profundidade m\u00e1xima de 3 para evitar overfitting.</p> </li> <li> <p>O modelo foi ajustado aos dados de treino.</p> </li> </ul>"},{"location":"classes/arvore-de-decisao/classificacao/#5-avaliacao-do-modelo","title":"5. Avalia\u00e7\u00e3o do Modelo","text":"<p>O desempenho do modelo foi avaliado com m\u00e9tricas de classifica\u00e7\u00e3o e visualiza\u00e7\u00e3o da \u00e1rvore.</p> OutputCodeExplica\u00e7\u00e3o <pre><code>Relat\u00f3rio de classifica\u00e7\u00e3o:\n            precision    recall  f1-score   support\n\n        0       0.78      0.78      0.78       286\n        1       0.64      0.61      0.62       274\n        2       0.85      0.88      0.86       319\n\n    accuracy                        0.76       879\nmacro avg       0.75      0.76      0.75       879\nweighted avg    0.76      0.76      0.76       879\n</code></pre> <pre><code>#fazer previs\u00f5es no conjunto de teste\ny_pred = clf.predict(X_test)\n\n#avalia\u00e7\u00e3o do modelo\nprint(\"Relat\u00f3rio de classifica\u00e7\u00e3o:\\n\", classification_report(y_test, y_pred))\n\n#visualiza\u00e7\u00e3o da \u00e1rvore de decis\u00e3o\nplt.figure(figsize=(16,8))\nplot_tree(clf, filled=True, fontsize=8, class_names=['Baixa','M\u00e9dia','Alta'])\nplt.savefig('./docs/classes/arvore-de-decisao/img/arvore_decisao.png')</code></pre> <ul> <li> <p>O modelo foi avaliado por m\u00e9tricas como precis\u00e3o, recall e F1-score.</p> </li> <li> <p>A acur\u00e1cia geral do modelo foi de 76%, indicando um bom desempenho na classifica\u00e7\u00e3o das casas em baixa, m\u00e9dia e alta renda.</p> </li> <li> <p>A precis\u00e3o e recall foram particularmente altos para a classe de alta renda, sugerindo que o modelo \u00e9 eficaz em identificar casas de maior valor.</p> </li> <li> <p>O F1-score para a classe de renda m\u00e9dia foi o mais baixo, refletindo a dificuldade em distinguir propriedades com caracter\u00edsticas intermedi\u00e1rias.</p> </li> </ul> <p></p> <p>O modelo de \u00e1rvore de decis\u00e3o desenvolvido para classificar as casas da base AmesHousing em tr\u00eas categorias \u2014 baixa, m\u00e9dia e alta renda \u2014 apresentou resultados bastante satisfat\u00f3rios e consistentes. A acur\u00e1cia global obtida foi de 76%, indicando que o modelo conseguiu aprender de forma eficiente os padr\u00f5es que distinguem as faixas de pre\u00e7o dos im\u00f3veis a partir de suas caracter\u00edsticas estruturais, de qualidade e localiza\u00e7\u00e3o.</p> <p>A an\u00e1lise das m\u00e9tricas por classe mostra um comportamento coerente com a natureza do problema. As casas de alta renda foram as mais bem classificadas, com precision de 0,85 e recall de 0,88, evidenciando que o modelo identifica de forma muito precisa os im\u00f3veis de maior valor. As casas de baixa renda tamb\u00e9m apresentaram um bom desempenho, com m\u00e9tricas equilibradas de precision e recall em torno de 0,78. J\u00e1 a faixa de renda m\u00e9dia foi a mais desafiadora, com F1-score de 0,62, o que \u00e9 esperado, pois essas propriedades possuem caracter\u00edsticas intermedi\u00e1rias que se sobrep\u00f5em \u00e0s das outras classes \u2014 tornando sua separa\u00e7\u00e3o menos evidente.</p> <p>A estrutura da \u00e1rvore de decis\u00e3o revela divis\u00f5es bastante intuitivas. Os principais crit\u00e9rios de separa\u00e7\u00e3o est\u00e3o relacionados a vari\u00e1veis como qualidade geral do im\u00f3vel (Overall Qual), \u00e1rea habit\u00e1vel (Gr Liv Area) e ano de constru\u00e7\u00e3o (Year Built), fatores que historicamente s\u00e3o determinantes para o valor de mercado de uma casa. O modelo dividiu os dados de forma l\u00f3gica: im\u00f3veis com menor qualidade e \u00e1rea ficaram concentrados nos n\u00f3s que levam \u00e0 classifica\u00e7\u00e3o de baixa renda, enquanto casas de padr\u00e3o superior e maior metragem foram alocadas nos ramos associados \u00e0 alta renda. As subdivis\u00f5es intermedi\u00e1rias formam os grupos de renda m\u00e9dia, onde a entropia \u00e9 mais alta, refletindo a maior mistura entre categorias.</p>"},{"location":"classes/arvore-de-decisao/classificacao/#51-importancia-das-variaveis","title":"5.1 Import\u00e2ncia das Vari\u00e1veis","text":"<p>A an\u00e1lise da import\u00e2ncia das vari\u00e1veis refor\u00e7a a relev\u00e2ncia dos atributos selecionados. A qualidade geral do im\u00f3vel (Overall Qual) foi a vari\u00e1vel mais influente, seguida pela \u00e1rea habit\u00e1vel (Gr Liv Area) e pelo ano de constru\u00e7\u00e3o (Year Built). Essas tr\u00eas vari\u00e1veis juntas explicam uma parcela significativa da capacidade preditiva do modelo. Outras caracter\u00edsticas, como o n\u00famero de banheiros, a presen\u00e7a de garagem e a localiza\u00e7\u00e3o (Neighborhood), tamb\u00e9m tiveram impacto relevante, embora em menor escala.</p>"},{"location":"classes/arvore-de-decisao/classificacao/#52-matriz-de-confusao","title":"5.2 Matriz de Confus\u00e3o","text":"<p>Mais detalhadamente, a matriz de confus\u00e3o revela que o modelo cometeu alguns erros de classifica\u00e7\u00e3o, especialmente entre as classes de baixa e m\u00e9dia renda. Houve uma quantidade consider\u00e1vel de casas de baixa renda que foram classificadas como m\u00e9dia renda, o que pode ser atribu\u00eddo \u00e0 sobreposi\u00e7\u00e3o das caracter\u00edsticas dessas categorias. No entanto, os erros entre baixa e alta renda foram m\u00ednimos, indicando que o modelo \u00e9 eficaz em distinguir extremos.</p>"},{"location":"classes/arvore-de-decisao/classificacao/#6-relatorio-final","title":"6. Relat\u00f3rio Final","text":"<p>Concluo que, visualmente, observa-se que a \u00e1rvore possui n\u00f3s bem definidos e relativamente puros, principalmente nas extremidades \u2014 o que refor\u00e7a a boa capacidade de discrimina\u00e7\u00e3o do modelo. O uso do crit\u00e9rio de entropia permitiu identificar divis\u00f5es que maximizam o ganho de informa\u00e7\u00e3o, resultando em agrupamentos coerentes e interpret\u00e1veis. A predomin\u00e2ncia de vari\u00e1veis de qualidade e tamanho nas decis\u00f5es internas indica que o modelo est\u00e1 de fato capturando a l\u00f3gica do mercado imobili\u00e1rio, em que o pre\u00e7o \u00e9 fortemente determinado por essas dimens\u00f5es.</p> <p>O modelo se mostra robusto, interpret\u00e1vel e eficiente para o objetivo proposto. Apesar de apresentar certa dificuldade na distin\u00e7\u00e3o entre as faixas m\u00e9dias de pre\u00e7o \u2014 algo comum em problemas desse tipo \u2014, o desempenho global \u00e9 satisfat\u00f3rio e demonstra que a \u00e1rvore de decis\u00e3o conseguiu aprender padr\u00f5es reais e relevantes presentes nos dados.</p>"},{"location":"classes/arvore-de-decisao/conceito/","title":"Conceito","text":""},{"location":"classes/arvore-de-decisao/conceito/#arvore-de-decisao","title":"\u00c1rvore de decis\u00e3o","text":"<p>As \u00e1rvores de decis\u00e3o s\u00e3o uma t\u00e9cnica popular de aprendizado de m\u00e1quina supervisionado usada para classifica\u00e7\u00e3o e regress\u00e3o. Elas representam decis\u00f5es e suas poss\u00edveis consequ\u00eancias em uma estrutura hier\u00e1rquica, facilitando a interpreta\u00e7\u00e3o dos resultados.</p>"},{"location":"classes/arvore-de-decisao/conceito/#funcionamento","title":"Funcionamento","text":"<ol> <li> <p>Divis\u00e3o Recursiva: A \u00e1rvore de decis\u00e3o come\u00e7a com um n\u00f3 raiz que representa todo o conjunto de dados. O algoritmo ent\u00e3o divide os dados em subconjuntos com base em uma feature que maximiza a separa\u00e7\u00e3o entre as classes (para classifica\u00e7\u00e3o) ou minimiza o erro (para regress\u00e3o). Esse processo \u00e9 repetido recursivamente para cada subconjunto, criando n\u00f3s filhos at\u00e9 que um crit\u00e9rio de parada seja atingido (como profundidade m\u00e1xima da \u00e1rvore ou n\u00famero m\u00ednimo de amostras em um n\u00f3).</p> </li> <li> <p>N\u00f3s e Folhas: Cada n\u00f3 interno representa uma decis\u00e3o baseada em uma feature, enquanto as folhas representam as previs\u00f5es finais (r\u00f3tulos de classe ou valores cont\u00ednuos).</p> </li> </ol>"},{"location":"classes/arvore-de-decisao/conceito/#vantagens-da-arvore-de-decisao","title":"Vantagens da \u00c1rvore de Decis\u00e3o \u2705","text":"<ul> <li>F\u00e1cil de interpretar e visualizar.</li> <li>Pode lidar com dados categ\u00f3ricos e num\u00e9ricos.</li> <li>Requer pouca prepara\u00e7\u00e3o de dados.</li> <li>Pode capturar rela\u00e7\u00f5es n\u00e3o lineares.</li> </ul>"},{"location":"classes/arvore-de-decisao/conceito/#desvantagens-da-arvore-de-decisao","title":"Desvantagens da \u00c1rvore de Decis\u00e3o \u274c","text":"<ul> <li>Propenso ao overfitting, especialmente com \u00e1rvores profundas.</li> <li>Sens\u00edvel a pequenas varia\u00e7\u00f5es nos dados.</li> <li>Pode ser inst\u00e1vel, pois pequenas mudan\u00e7as nos dados podem levar a \u00e1rvores muito diferentes.</li> </ul>"},{"location":"classes/arvore-de-decisao/conceito/#metricas-de-avaliacao-da-arvore-de-decisao","title":"M\u00e9tricas de Avalia\u00e7\u00e3o da \u00c1rvore de Decis\u00e3o","text":"<p>Entropia: A entropia \u00e9 uma medida da incerteza ou impureza em um conjunto de dados. Em termos simples, ela quantifica o grau de desordem ou aleatoriedade em um sistema. Em aprendizado de m\u00e1quina, a entropia \u00e9 usada para avaliar a qualidade das divis\u00f5es em uma \u00e1rvore de decis\u00e3o.</p> <p>Ganho de Informa\u00e7\u00e3o: O ganho de informa\u00e7\u00e3o \u00e9 uma m\u00e9trica que quantifica a redu\u00e7\u00e3o da entropia ap\u00f3s uma divis\u00e3o dos dados com base em uma feature espec\u00edfica. Em outras palavras, ele mede o quanto a incerteza sobre a vari\u00e1vel alvo diminui quando os dados s\u00e3o divididos com base em uma determinada feature. O ganho de informa\u00e7\u00e3o \u00e9 calculado como a diferen\u00e7a entre a entropia do conjunto de dados original e a entropia ponderada dos subconjuntos resultantes da divis\u00e3o.</p> <p>\u00cdndice Gini: O \u00edndice Gini \u00e9 uma medida de impureza ou pureza usada em \u00e1rvores de decis\u00e3o para avaliar a qualidade das divis\u00f5es dos dados. Ele quantifica a probabilidade de um elemento ser classificado incorretamente se fosse rotulado aleatoriamente de acordo com a distribui\u00e7\u00e3o das classes no conjunto de dados. O \u00edndice Gini varia entre 0 (pureza m\u00e1xima, onde todos os elementos pertencem \u00e0 mesma classe) e 0,5 (impureza m\u00e1xima, onde as classes est\u00e3o igualmente distribu\u00eddas).</p>"},{"location":"classes/conceitos/main/","title":"Conceitos Iniciais","text":""},{"location":"classes/conceitos/main/#conceitos-basicos","title":"Conceitos b\u00e1sicos","text":"<p>Estes s\u00e3o os conceitos da mat\u00e9ria de Machine Learning para que eu conseguisse elaborar os exerc\u00edcios cobrados na mat\u00e9ria.</p>"},{"location":"classes/conceitos/main/#sobre-ia","title":"Sobre IA","text":"<p>A Intelig\u00eancia Artificial serve para automatizar a m\u00e3o de obra humana. Ela pode ser categorizada em:</p> <ol> <li> <p>Symbolic IA: se concentra em representar o conhecimento da IA por meio de s\u00edmbolos e regras. Usamos aqui o conhecimento do primeiro semestre da tabela verdade para saber se uma proposi\u00e7\u00e3o \u00e9 verdadeira ou falsa.</p> </li> <li> <p>Connectionist AI: \u00e9 a IA baseada em redes neurais e se concentra em c\u00e1lculos e infer\u00eancias matem\u00e1ticas.</p> </li> <li> <p>Neuro-Symbolic AI: \u00e9 a intersec\u00e7\u00e3o entre o racioc\u00ednio simb\u00f3lico com as redes neurais, o que potencializa os pontos fortes das outras IA's para que a Neuro-Symbolic AI consiga resolver problemas complexos e ao mesmo tempo aprender com os dados.</p> </li> </ol> <p></p>"},{"location":"classes/conceitos/main/#machine-learning","title":"Machine Learning","text":"<p>Mas, o que \u00e9 o Machine Learning?</p> <p>Esta t\u00e9cnica serve para que a m\u00e1quina aprenda a partir dos dados, com o intuito de que o sistema consiga resolver problemas mais complexos e que melhorem seu desemepenho, sem que sejam programados necessariamente o tempo todo de execu\u00e7\u00e3o.</p> <p>Dentro do Machine Learning, as t\u00e9cnicas s\u00e3o divididas em duas grandes categorias principais: o aprendizado supervisionado e o aprendizado n\u00e3o supervisionado.</p> <p>Aprendizado supervisionado</p> <p>O aprendizado supervisionado \u00e9 quando treinamos um modelo com uma base de dados rotulados. Isso faz com que o sistema aprenda os padr\u00f5es e fa\u00e7a previs\u00f5es com uma base de dados novas e in\u00e9ditas.</p> <p>USADO EM: tarefas de classifica\u00e7\u00e3o e tarefas de regress\u00e3o. -&gt; abordagem eficaz quando existe uma rela\u00e7\u00e3o entre as vari\u00e1veis feature e target.</p> <ul> <li>Os dados rotulados nada mais s\u00e3o do que o conjunto em que cada linha tem um valor de resposta correto, que voc\u00ea usa para ensinar o modelo. A vari\u00e1vel target \u00e9 considerada como o r\u00f3tulo, por ser a vari\u00e1vel resposta.</li> </ul> <p>Aprendizado n\u00e3o supervisionado</p> <p>O aprendizado n\u00e3o supervisionado envolve uma base de dados n\u00e3o rotulada, ou seja, o pr\u00f3prio modelo deve encontrar padr\u00f5es e relacionamentos dentro dos dados que n\u00e3o tem uma orienta\u00e7\u00e3o expl\u00edcita.</p> <p>USADO EM: an\u00e1lises explorat\u00f3rias de dados e extra\u00e7\u00e3o de recursos (clusteriza\u00e7\u00e3o e redu\u00e7\u00e3o de n\u00famero de recursos em um conjunto de dados) -&gt; abordagem eficaz quando temos que descobrir estruturas ocultas em uma base de dados.</p> <p>Aprendizado por refor\u00e7o</p> <p>Essa t\u00e9cnica \u00e9 mais comumente utilizada quando o sistema precisa tomar decis\u00f5es sequenciais com o ambiente e receber um feedback na forma de ganho ou perca.</p> <p>USADO EM: jogos ou controle rob\u00f3tico.</p> <p>As t\u00e9cnicas para aprendizado da m\u00e1quina resolve uma variedade de problemas, e os principais deles s\u00e3o:</p> <ul> <li> <p>Problema de classifica\u00e7\u00e3o: envolve a previs\u00e3o de categorias discretas (valores inteiros) ou r\u00f3tulos futuros com base na feature.</p> </li> <li> <p>Problema de regress\u00e3o: envolve a previs\u00e3o de valores cont\u00ednuos.</p> </li> </ul>"},{"location":"classes/conceitos/main/#modelos","title":"Modelos","text":"<p>Temos modelos que s\u00e3o com aprendizado supervisionado e com aprendizado n\u00e3o supervisionado. Veja a distribui\u00e7\u00e3o dos algoritmos:</p> <p>Para a constru\u00e7\u00e3o dos modelos, normalmente seguimos algumas etapas. S\u00e3o elas:</p> <p></p> <ol> <li> <p>Explora\u00e7\u00e3o dos Dados (EDA): Nesta etapa, os dados s\u00e3o analisados para entender suas caracter\u00edsticas, identificar padr\u00f5es e detectar poss\u00edveis problemas, como: valores ausentes ou outliers.</p> </li> <li> <p>Pr\u00e9-processamento: Os dados s\u00e3o limpos e preparados para a modelagem. Isso pode incluir a normaliza\u00e7\u00e3o, transforma\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas em num\u00e9ricas (usando t\u00e9cnicas como One-Hot Encoding ou Label Encoding), tratamento dos valores ausentes. Comparativo T\u00e9cnico: Label Encoding vs One Hot Encoding/</p> </li> <li> <p>Modelagem: A \u00e1rvore de decis\u00e3o \u00e9 constru\u00edda a partir dos dados de treinamento. O algoritmo seleciona as features que melhor dividem os dados em cada n\u00f3, com base em crit\u00e9rios como entropia e ganho de informa\u00e7\u00e3o.</p> </li> <li> <p>Resultados: O modelo \u00e9 avaliado usando o conjunto de teste para medir sua precis\u00e3o e capacidade de generaliza\u00e7\u00e3o. M\u00e9tricas como acur\u00e1cia, precis\u00e3o, recall e F1-score s\u00e3o comumente usadas.</p> </li> <li> <p>Melhorias: Nesta etapa, \u00e9 importante revisarmos os resultados do modelo e ver se tem como fazer melhorias, como tirar algumas vari\u00e1veis insignificantes e etc.</p> </li> <li> <p>Conclus\u00e3o: Os resultados s\u00e3o interpretados e as decis\u00f5es s\u00e3o tomadas com base nas previs\u00f5es do modelo. A \u00e1rvore de decis\u00e3o pode ser visualizada para entender como as decis\u00f5es foram feitas.</p> </li> </ol>"},{"location":"classes/conceitos/main/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Machine Learning Mastery - Decision Trees</li> <li>Machine Learning Mastery - KNN</li> <li>Machine Learning Mastery - K-Means</li> <li>Scikit-Learn - Decision Trees</li> <li>Scikit-Learn - KNN</li> <li>Scikit-Learn - K-Means</li> <li>Wikipedia - Decision Trees</li> <li>Wikipedia - KNN</li> <li>Wikipedia - K-Means</li> <li>Towards Data Science - Decision Trees</li> <li>Towards Data Science - KNN</li> <li>Towards Data Science - K-Means</li> <li>GeeksforGeeks - Decision Trees</li> <li>GeeksforGeeks - KNN</li> <li>GeeksforGeeks - K-Means</li> </ul>"},{"location":"classes/gradient/conceito/","title":"Conceito","text":""},{"location":"classes/gradient/conceito/#gradient-boosting","title":"Gradient Boosting","text":"<p>A t\u00e9cnica do Gradient Boosting.</p>"},{"location":"classes/gradient/main/","title":"Projeto","text":""},{"location":"classes/k-means/conceito/","title":"Conceito","text":""},{"location":"classes/k-means/conceito/#k-means","title":"K-Means","text":"<p>O K-Means \u00e9 um algoritmo de aprendizado n\u00e3o supervisionado usado para tarefas de clusteriza\u00e7\u00e3o. Ele agrupa dados em K clusters distintos com base na similaridade das caracter\u00edsticas dos dados. O objetivo do K-Means \u00e9 minimizar a vari\u00e2ncia dentro de cada cluster, ou seja, os pontos dentro de um cluster devem ser o mais semelhantes poss\u00edvel entre si.</p>"},{"location":"classes/k-means/conceito/#funcionamento","title":"Funcionamento","text":"<ol> <li> <p>Inicializa\u00e7\u00e3o: O algoritmo come\u00e7a escolhendo K centr\u00f3ides iniciais aleat\u00f3rios a partir dos dados.</p> </li> <li> <p>Atribui\u00e7\u00e3o de Cluster: Cada ponto de dado \u00e9 atribu\u00eddo ao cluster cujo centr\u00f3ide est\u00e1 mais pr\u00f3ximo. Essa proximidade \u00e9 geralmente medida usando a dist\u00e2ncia Euclidiana.</p> </li> <li> <p>Atualiza\u00e7\u00e3o de Centr\u00f3ides: Ap\u00f3s a atribui\u00e7\u00e3o, os centr\u00f3ides de cada cluster s\u00e3o recalculados como a m\u00e9dia dos pontos atribu\u00eddos a eles.</p> </li> <li> <p>Converg\u00eancia: Os passos 2 e 3 s\u00e3o repetidos at\u00e9 que os centr\u00f3ides n\u00e3o mudem significativamente ou at\u00e9 que um n\u00famero m\u00e1ximo de itera\u00e7\u00f5es seja alcan\u00e7ado.</p> </li> </ol>"},{"location":"classes/k-means/conceito/#vantagens-do-k-means","title":"Vantagens do K-Means \u2705","text":"<ul> <li>Simplicidade: O K-Means \u00e9 f\u00e1cil de entender e implementar.</li> <li>Escalabilidade: Funciona bem em grandes conjuntos de dados.</li> <li>Efici\u00eancia: O algoritmo \u00e9 relativamente r\u00e1pido, especialmente com implementa\u00e7\u00f5es otimizadas.</li> </ul>"},{"location":"classes/k-means/conceito/#desvantagens-do-k-means","title":"Desvantagens do K-Means \u274c","text":"<ul> <li>Escolha do K: A determina\u00e7\u00e3o do n\u00famero ideal de clusters (K) pode ser desafiadora.</li> <li>Sensibilidade a outliers: O K-Means pode ser influenciado por valores extremos.</li> <li>Forma dos Clusters: O algoritmo assume que os clusters t\u00eam formas esf\u00e9ricas e tamanhos semelhantes, o que nem sempre \u00e9 o caso na pr\u00e1tica.</li> <li>Inicializa\u00e7\u00e3o Aleat\u00f3ria: A escolha inicial dos centr\u00f3ides pode afetar os resultados, levando a diferentes solu\u00e7\u00f5es em execu\u00e7\u00f5es diferentes.</li> </ul>"},{"location":"classes/k-means/conceito/#metricas-para-avaliacao-de-clusters","title":"M\u00e9tricas para Avalia\u00e7\u00e3o de Clusters","text":"<p>As m\u00e9tricas mais comuns para avaliar a qualidade dos clusters formados pelo K-Means incluem:</p> <ul> <li> <p>In\u00e9rcia: Mede a soma das dist\u00e2ncias quadr\u00e1ticas entre os pontos e seus respectivos centr\u00f3ides. Menores valores de in\u00e9rcia indicam clusters mais compactos.</p> </li> <li> <p>Silhueta: Avalia a qualidade dos clusters, considerando a coes\u00e3o (dist\u00e2ncia m\u00e9dia entre pontos dentro do mesmo cluster) e a separa\u00e7\u00e3o (dist\u00e2ncia m\u00e9dia entre pontos de diferentes clusters). Valores pr\u00f3ximos de 1 indicam clusters bem definidos, enquanto valores pr\u00f3ximos de -1 indicam clusters mal definidos.</p> </li> <li> <p>\u00cdndice de Dunn: Mede a raz\u00e3o entre a menor dist\u00e2ncia entre pontos de diferentes clusters e a maior dist\u00e2ncia dentro de um cluster. Valores mais altos indicam melhores separa\u00e7\u00f5es entre clusters.</p> </li> </ul>"},{"location":"classes/k-means/conceito/#metodo-do-cotovelo-elbow-method","title":"M\u00e9todo do Cotovelo (Elbow Method)","text":"<p>O M\u00e9todo do Cotovelo \u00e9 uma t\u00e9cnica visual usada para determinar o n\u00famero ideal de clusters (K) em um conjunto de dados ao usar o algoritmo K-Means. A ideia \u00e9 executar o K-Means para diferentes valores de K e plotar a in\u00e9rcia (soma das dist\u00e2ncias quadr\u00e1ticas entre os pontos e seus respectivos centr\u00f3ides) em fun\u00e7\u00e3o de K. \u00c0 medida que K aumenta, a in\u00e9rcia tende a diminuir, pois os clusters se tornam mais espec\u00edficos.</p> <p>O ponto onde a taxa de diminui\u00e7\u00e3o da in\u00e9rcia come\u00e7a a desacelerar significativamente \u00e9 chamado de \"cotovelo\". Esse ponto sugere um valor apropriado para K, pois indica que adicionar mais clusters al\u00e9m desse ponto n\u00e3o resulta em uma melhoria substancial na compacta\u00e7\u00e3o dos clusters.</p> <p><code>mermaid graph TD     A[In\u00e9rcia] --&gt; B[Cotovelo]     B --&gt; C[N\u00famero Ideal de Clusters (K)]</code></p>"},{"location":"classes/k-means/conceito/#aplicacoes-do-k-means","title":"Aplica\u00e7\u00f5es do K-Means","text":"<p>O K-Means \u00e9 amplamente utilizado em diversas \u00e1reas, incluindo:</p> <ul> <li>Segmenta\u00e7\u00e3o de Clientes: Agrupar clientes com base em comportamentos de compra semelhantes.</li> <li>Compress\u00e3o de Imagens: Reduzir o n\u00famero de cores em uma imagem, agrupando pixels semelhantes.</li> <li>An\u00e1lise de Texto: Agrupar documentos ou textos semelhantes para facilitar a busca e a organiza\u00e7\u00e3o.</li> <li>Detec\u00e7\u00e3o de Anomalias: Identificar padr\u00f5es incomuns em dados, como fraudes financeiras.</li> <li>Agrupamento Geogr\u00e1fico: Agrupar locais com base em caracter\u00edsticas geogr\u00e1ficas ou demogr\u00e1ficas.</li> <li>Recomenda\u00e7\u00f5es de Produtos: Agrupar produtos semelhantes para melhorar sistemas de recomenda\u00e7\u00e3o.</li> <li>An\u00e1lise de Redes Sociais: Identificar comunidades ou grupos de usu\u00e1rios com interesses semelhantes.</li> <li>Biologia e Gen\u00f4mica: Agrupar genes ou prote\u00ednas com fun\u00e7\u00f5es semelhantes para facilitar a an\u00e1lise biol\u00f3gica.</li> <li>Marketing: Identificar segmentos de mercado para campanhas direcionadas.</li> <li>Sa\u00fade: Agrupar pacientes com caracter\u00edsticas semelhantes para personalizar tratamentos m\u00e9dicos.</li> <li>Ci\u00eancia de Dados: Explorar e entender grandes conjuntos de dados, identificando padr\u00f5es e tend\u00eancias.</li> <li>Finan\u00e7as: Agrupar ativos financeiros com comportamentos semelhantes para otimizar portf\u00f3lios de investimento.</li> <li>Log\u00edstica: Otimizar rotas de entrega agrupando destinos pr\u00f3ximos.</li> <li>Educa\u00e7\u00e3o: Agrupar estudantes com base em desempenho ou estilos de aprendizagem para personalizar o ensino.</li> </ul>"},{"location":"classes/k-means/main/","title":"Projeto","text":""},{"location":"classes/k-means/main/#projeto-de-classificacao-de-casas-com-k-means","title":"Projeto de Classifica\u00e7\u00e3o de Casas com K-Means","text":"<p>Este projeto utiliza o algoritmo K-Means para agrupar casas com base em suas caracter\u00edsticas e prever a faixa de pre\u00e7o (baixa, m\u00e9dia, alta) no dataset Ames Housing. O objetivo \u00e9 demonstrar como o K-Means pode ser aplicado em um problema de classifica\u00e7\u00e3o n\u00e3o supervisionada.</p>"},{"location":"classes/k-means/main/#exploracao-dos-dados-eda","title":"Explora\u00e7\u00e3o dos Dados (EDA)","text":"<p>O dataset Ames Housing cont\u00e9m diversas caracter\u00edsticas das casas, como \u00e1rea, n\u00famero de quartos, idade, entre outras. A an\u00e1lise explorat\u00f3ria dos dados (EDA) foi realizada para entender a distribui\u00e7\u00e3o das caracter\u00edsticas e identificar poss\u00edveis correla\u00e7\u00f5es com o pre\u00e7o das casas.</p> <p>Toda esta etapa foi realizada no arquivo Explora\u00e7\u00e3o dos Dados (EDA).</p>"},{"location":"classes/k-means/main/#pre-processamento-dos-dados","title":"Pr\u00e9-processamento dos Dados","text":"<p>O dataset foi carregado e pr\u00e9-processado para remover valores ausentes e normalizar as caracter\u00edsticas. As principais etapas incluem:</p> <ol> <li>Carregamento do dataset.</li> <li>Tratamento de valores ausentes.</li> <li>Normaliza\u00e7\u00e3o das caracter\u00edsticas.</li> <li>Sele\u00e7\u00e3o das caracter\u00edsticas relevantes para o modelo.</li> <li>Aplica\u00e7\u00e3o do K-Means para agrupar as casas.</li> <li>An\u00e1lise dos clusters formados e suas caracter\u00edsticas m\u00e9dias.</li> <li>Avalia\u00e7\u00e3o do modelo com base na distribui\u00e7\u00e3o dos clusters em rela\u00e7\u00e3o \u00e0s faixas de pre\u00e7o.</li> <li>Visualiza\u00e7\u00e3o dos resultados.</li> </ol> <p>As etapas 2, 3 e 4 foram realizadas no arquivo Pr\u00e9-processamento dos Dados. J\u00e1 a etapa de sele\u00e7\u00e3o das vari\u00e1veis foi realizada no arquivo Sele\u00e7\u00e3o de Vari\u00e1veis.</p> OutputCode <pre><code>    Valores ausentes por coluna:\n    MS SubClass        0\n    MS Zoning          0\n    Lot Frontage       0\n    Lot Area           0\n    Street             0\n    Lot Shape          0\n    Land Contour       0\n    Utilities          0\n    Lot Config         0\n    Land Slope         0\n    Neighborhood       0\n    Condition 1        0\n    Condition 2        0\n    Bldg Type          0\n    House Style        0\n    Overall Qual       0\n    Overall Cond       0\n    Year Built         0\n    Year Remod/Add     0\n    Roof Style         0\n    Roof Matl          0\n    Exterior 1st       0\n    Exterior 2nd       0\n    Mas Vnr Type       0\n    Mas Vnr Area       0\n    Exter Qual         0\n    Exter Cond         0\n    Foundation         0\n    Bsmt Qual          0\n    Bsmt Cond          0\n    Bsmt Exposure      0\n    BsmtFin Type 1     0\n    BsmtFin SF 1       0\n    BsmtFin Type 2     0\n    BsmtFin SF 2       0\n    Bsmt Unf SF        0\n    Total Bsmt SF      0\n    Heating            0\n    Heating QC         0\n    Central Air        0\n    Electrical         0\n    1st Flr SF         0\n    2nd Flr SF         0\n    Low Qual Fin SF    0\n    Gr Liv Area        0\n    Bsmt Full Bath     0\n    Bsmt Half Bath     0\n    Full Bath          0\n    Half Bath          0\n    Bedroom AbvGr      0\n    Kitchen AbvGr      0\n    Kitchen Qual       0\n    TotRms AbvGrd      0\n    Functional         0\n    Fireplaces         0\n    Garage Type        0\n    Garage Yr Blt      0\n    Garage Finish      0\n    Garage Cars        0\n    Garage Area        0\n    Garage Qual        0\n    Garage Cond        0\n    Paved Drive        0\n    Wood Deck SF       0\n    Open Porch SF      0\n    Enclosed Porch     0\n    3Ssn Porch         0\n    Screen Porch       0\n    Pool Area          0\n    Misc Val           0\n    Mo Sold            0\n    Yr Sold            0\n    Sale Type          0\n    Sale Condition     0\n    SalePrice          0\n\n    Total de linhas ap\u00f3s remo\u00e7\u00e3o: 2930\n\n            MS SubClass  Lot Frontage  Lot Area  Overall Qual  Overall Cond  \\\n    0           20         141.0     31770             6             5   \n    1           20          80.0     11622             5             6   \n    2           20          81.0     14267             6             6   \n    3           20          93.0     11160             7             5   \n    4           60          74.0     13830             5             5   \n    5           60          78.0      9978             6             6   \n    6          120          41.0      4920             8             5   \n    7          120          43.0      5005             8             5   \n    8          120          39.0      5389             8             5   \n    9           60          60.0      7500             7             5   \n\n    Year Built  Year Remod/Add  Mas Vnr Area  Exter Qual  Exter Cond  ...  \\\n    0        1960            1960         112.0           3           3  ...   \n    1        1961            1961           0.0           3           3  ...   \n    2        1958            1958         108.0           3           3  ...   \n    3        1968            1968           0.0           4           3  ...   \n    4        1997            1998           0.0           3           3  ...   \n    5        1998            1998          20.0           3           3  ...   \n    6        2001            2001           0.0           4           3  ...   \n    7        1992            1992           0.0           4           3  ...   \n    8        1995            1996           0.0           4           3  ...   \n    9        1999            1999           0.0           3           3  ...   \n\n    Sale Type_New  Sale Type_Oth  Sale Type_VWD  Sale Type_WD   \\\n    0          False          False          False           True   \n    1          False          False          False           True   \n    2          False          False          False           True   \n    3          False          False          False           True   \n    4          False          False          False           True   \n    5          False          False          False           True   \n    6          False          False          False           True   \n    7          False          False          False           True   \n    8          False          False          False           True   \n    9          False          False          False           True   \n\n    Sale Condition_Abnorml  Sale Condition_AdjLand  Sale Condition_Alloca  \\\n    0                   False                   False                  False   \n    1                   False                   False                  False   \n    2                   False                   False                  False   \n    3                   False                   False                  False   \n    4                   False                   False                  False   \n    5                   False                   False                  False   \n    6                   False                   False                  False   \n    7                   False                   False                  False   \n    8                   False                   False                  False   \n    9                   False                   False                  False   \n\n    Sale Condition_Family  Sale Condition_Normal  Sale Condition_Partial  \n    0                  False                   True                   False  \n    1                  False                   True                   False  \n    2                  False                   True                   False  \n    3                  False                   True                   False  \n    4                  False                   True                   False  \n    5                  False                   True                   False  \n    6                  False                   True                   False  \n    7                  False                   True                   False  \n    8                  False                   True                   False  \n    9                  False                   True                   False  \n\n    [10 rows x 233 columns]\n</code></pre> <pre><code>\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from sklearn.cluster import KMeans\n\n    df = pd.read_csv('/home/mgabriel4/Documentos/GitHub/machine-learning/data/AmesHousing.csv')\n\n    df = df.drop(columns=['Order', 'PID'])\n    df = df.drop(columns=['Pool QC', 'Misc Feature', 'Alley', 'Fence', 'Fireplace Qu'])\n\n    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n    for col in num_cols:\n        df[col].fillna(df[col].median(), inplace=True)\n\n    cat_cols = df.select_dtypes(include=['object']).columns\n    for col in cat_cols:\n        df[col].fillna(df[col].mode()[0], inplace=True)\n\n    nulos = df.isnull().sum()\n    print(\"\\nValores ausentes por coluna:\")\n    print(nulos.head(100).to_string())\n    print(f\"\\nTotal de linhas ap\u00f3s remo\u00e7\u00e3o: {len(df)}\")\n\n    variaveis_ordinal = {\n        'Exter Qual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n        'Exter Cond': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n        'Bsmt Qual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n        'Bsmt Cond': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n        'Heating QC': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n        'Kitchen Qual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n        'Garage Qual': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n        'Garage Cond': {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5},\n        'Bsmt Exposure': {'No':1, 'Mn':2, 'Av':3, 'Gd':4},\n        'BsmtFin Type 1': {'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6},\n        'BsmtFin Type 2': {'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6},\n        'Functional': {'Sal':1, 'Sev':2, 'Maj2':3, 'Maj1':4, 'Mod':5, 'Min2':6, 'Min1':7, 'Typ':8},\n    }\n\n    for col, mapping in variaveis_ordinal.items():\n        if col in df.columns:\n            df[col] = df[col].map(mapping).fillna(0).astype(int)\n\n    variaveis_nominais = [\n        'MS Zoning', 'Street', 'Lot Shape', 'Land Contour',\n        'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood', 'Condition 1',\n        'Condition 2', 'Bldg Type', 'House Style', 'Roof Style', 'Roof Matl',\n        'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation',\n        'Heating', 'Central Air', 'Electrical', 'Garage Type', 'Garage Finish',\n        'Paved Drive', 'Sale Type', 'Sale Condition'\n    ]\n\n    df = pd.get_dummies(df, columns=variaveis_nominais)\n\n    print(df.head(10))\n</code></pre>"},{"location":"classes/k-means/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Os dados foram divididos em vari\u00e1veis independentes (X) e a vari\u00e1vel dependente (y), que representa a faixa de pre\u00e7o das casas. A vari\u00e1vel dependente foi categorizada em tr\u00eas classes: baixa, m\u00e9dia e alta.</p> <p>A sele\u00e7\u00e3o das vari\u00e1veis independentes mais importantes foi realizada no arquivo Sele\u00e7\u00e3o de Vari\u00e1veis.</p> Code <pre><code>\n    df['Target'] = pd.qcut(df['SalePrice'], q=3, labels=['Baixa', 'M\u00e9dia', 'Alta'])\n\n    df['Target'] = df['Target'].map({'Baixa':0, 'M\u00e9dia':1, 'Alta':2}).astype('int')\n\n    x = df[['Overall Qual', 'Year Built', 'Exter Qual', 'Bsmt Qual', 'Gr Liv Area', 'Full Bath', 'Kitchen Qual', 'Garage Cars', 'Garage Area', 'Garage Finish_Unf']]\n    y = df['Target'].values.astype('int')\n</code></pre>"},{"location":"classes/k-means/main/#treinamento-do-modelo","title":"Treinamento do modelo","text":"<p>O modelo K-Means tem que ser treinado com o n\u00famero de clusters (k) definido, pela t\u00e9cnica do Elbow Curve. Logo ap\u00f3s o treinamento, os clusters formados foram analisados para entender suas caracter\u00edsticas m\u00e9dias.</p>"},{"location":"classes/k-means/main/#metodo-elbow-curve","title":"M\u00e9todo Elbow Curve","text":"<p>Utilizamos este m\u00e9todo para determinar o n\u00famero ideal de clusters (k) para o K-Means. O gr\u00e1fico do Elbow Curve mostra a soma dos quadrados dentro do cluster (inertia) em fun\u00e7\u00e3o do n\u00famero de clusters. O ponto onde a redu\u00e7\u00e3o da inertia come\u00e7a a diminuir significativamente indica o valor ideal de k.</p> Code <pre><code>\n    inertia = []\n    K = range(1, 10)\n\n    for k in K:\n        kmeans = KMeans(n_clusters=k, random_state=42)\n        kmeans.fit(x)\n        inertia.append(kmeans.inertia_)\n\n    plt.plot(K, inertia, 'bo-')\n    plt.xlabel('N\u00famero de clusters (K)')\n    plt.ylabel('In\u00e9rcia (Soma das Dist\u00e2ncias)')\n    plt.title('M\u00e9todo do Cotovelo')\n    plt.savefig('/home/mgabriel4/Documentos/GitHub/machine-learning/docs/classes/k-means/img/elbow_method.png')\n    plt.show()\n</code></pre> <p></p> <p>A partir do gr\u00e1fico, escolhemos k=3 para o modelo K-Means.</p>"},{"location":"classes/k-means/main/#aplicacao-do-k-means","title":"Aplica\u00e7\u00e3o do K-Means","text":"<p>O modelo K-Means foi treinado com k=3 clusters. Ap\u00f3s o treinamento, os clusters foram analisados para entender suas caracter\u00edsticas m\u00e9dias.</p> OutputCode <pre><code>    1    1040\n    0     966\n    2     924\n    Name: Cluster, dtype: int64\n</code></pre> <pre><code>\n    kmeans = KMeans(n_clusters=3, random_state=42)\n    df['Cluster'] = kmeans.fit_predict(x)\n\n    print(df['Cluster'].value_counts())\n    print(df.groupby('Cluster')[x.columns].mean())\n\n    sns.scatterplot(\n        data=df, x='Gr Liv Area', y='SalePrice',\n        hue='Cluster', palette='viridis'\n    )\n    plt.title('Clusters - KMeans')\n    plt.savefig('/home/mgabriel4/Documentos/GitHub/machine-learning/docs/classes/k-means/img/kmeans_clusters.png')\n    plt.show()\n</code></pre> <p></p> <p>Interpretamos os clusters formados:</p> <ul> <li>Cluster 0: Casas com qualidade geral e \u00e1rea de estar menores, provavelmente correspondendo \u00e0 faixa de pre\u00e7o baixa.</li> <li>Cluster 1: Casas com qualidade geral e \u00e1rea de estar intermedi\u00e1rias, provavelmente correspondendo \u00e0 faixa de pre\u00e7o m\u00e9dia.</li> <li>Cluster 2: Casas com qualidade geral e \u00e1rea de estar maiores, provavelmente correspondendo \u00e0 faixa de pre\u00e7o alta.</li> </ul>"},{"location":"classes/k-means/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>A avalia\u00e7\u00e3o do modelo foi feita analisando a distribui\u00e7\u00e3o dos clusters em rela\u00e7\u00e3o \u00e0s faixas de pre\u00e7o (baixa, m\u00e9dia, alta). Observamos que os clusters formados pelo K-Means correspondem razoavelmente bem \u00e0s categorias de pre\u00e7o.</p> OutputCode <pre><code>    Cluster 0:\n    Baixa: 0\n    M\u00e9dia: 273\n    Alta: 726\n\n    Cluster 1:\n    Baixa: 0\n    M\u00e9dia: 0\n    Alta: 243\n\n    Cluster 2:\n    Baixa: 981\n    M\u00e9dia: 707\n    Alta: 0\n</code></pre> <pre><code>\n    for cluster in range(3):\n        subset = df[df['Cluster'] == cluster]\n        counts = subset['Target'].value_counts().sort_index()\n        print(f\"\\nCluster {cluster}:\")\n        print(f\"Baixa: {counts.get(0, 0)}\")\n        print(f\"M\u00e9dia: {counts.get(1, 0)}\")\n        print(f\"Alta: {counts.get(2, 0)}\")\n\n    df.groupby('Cluster')[x.columns].mean()\n</code></pre> <p></p> <p>Vemos que o modelo K-Means conseguiu agrupar as casas de forma que os clusters correspondem \u00e0s faixas de pre\u00e7o, embora haja alguma sobreposi\u00e7\u00e3o. Isso indica que o K-Means pode ser \u00fatil para segmentar o mercado imobili\u00e1rio com base em caracter\u00edsticas das casas.</p>"},{"location":"classes/knn/conceito/","title":"Conceito","text":""},{"location":"classes/knn/conceito/#knn-k-nearest-neighbors","title":"KNN (K-Nearest Neighbors)","text":"<p>O KNN \u00e9 um algoritmo de aprendizado supervisionado usado para problemas de classifica\u00e7\u00e3o e regress\u00e3o. Ele \u00e9 baseado na ideia de que objetos semelhantes est\u00e3o pr\u00f3ximos uns dos outros no espa\u00e7o de caracter\u00edsticas. \u00c9 v\u00e1lido ressaltar que o KNN \u00e9 bom para conjuntos de dados pequenos e m\u00e9dios, e \u00e9 simples de entender e implementar.</p>"},{"location":"classes/knn/conceito/#funcionamento","title":"Funcionamento","text":"<ol> <li> <p>Escolha do K: O primeiro passo \u00e9 escolher o n\u00famero de vizinhos (K) que ser\u00e3o considerados para a classifica\u00e7\u00e3o ou regress\u00e3o. Este passo \u00e9 crucial, pois um valor muito pequeno pode tornar o modelo sens\u00edvel ao ru\u00eddo, enquanto um valor muito grande pode suavizar demais as fronteiras de decis\u00e3o. Para que n\u00e3o haja uma escolha do K equivocada, faz-se a t\u00e9cnica de valida\u00e7\u00e3o cruzada.</p> </li> <li> <p>C\u00e1lculo da Dist\u00e2ncia: Para classificar um novo ponto, o algoritmo calcula a dist\u00e2ncia entre esse ponto e todos os pontos do conjunto de treinamento. As m\u00e9tricas de dist\u00e2ncias mais comuns s\u00e3o a Euclidiana, Manhattan e Minkowski.</p> </li> <li> <p>Identifica\u00e7\u00e3o dos Vizinhos: O algoritmo seleciona os K pontos mais pr\u00f3ximos do conjunto de treinamento.</p> </li> <li> <p>Classifica\u00e7\u00e3o ou Regress\u00e3o:</p> </li> <li>Classifica\u00e7\u00e3o: O r\u00f3tulo do novo ponto \u00e9 determinado pelos r\u00f3tulos frequentes dos K vizinhos. (Ou seja, a moda dos r\u00f3tulos)</li> <li>Regress\u00e3o: O valor do novo ponto \u00e9 determinado pela m\u00e9dia (ou mediana) dos valores dos K vizinhos.</li> </ol>"},{"location":"classes/knn/conceito/#vantagens-do-knn","title":"Vantagens do KNN \u2705","text":"<ul> <li>Simplicidade: O KNN \u00e9 f\u00e1cil de entender e implementar.</li> <li>Flexibilidade: Pode ser usado para classifica\u00e7\u00e3o e regress\u00e3o.</li> <li>N\u00e3o param\u00e9trico: N\u00e3o faz suposi\u00e7\u00f5es sobre a distribui\u00e7\u00e3o dos dados.</li> </ul>"},{"location":"classes/knn/conceito/#desvantagens-do-knn","title":"Desvantagens do KNN \u274c","text":"<ul> <li>Custo computacional: O KNN pode ser lento, especialmente com grandes conjuntos de dados, pois precisa calcular a dist\u00e2ncia de todos os pontos.</li> <li>Sensibilidade a ru\u00eddos: O algoritmo pode ser afetado por outliers e ru\u00eddos nos dados.</li> <li>Escolha do K: A escolha do valor de K pode impactar significativamente o desempenho do modelo.</li> </ul>"},{"location":"classes/knn/conceito/#metricas-de-avaliacao","title":"M\u00e9tricas de Avalia\u00e7\u00e3o","text":"<p>As m\u00e9tricas de avalia\u00e7\u00e3o para KNN incluem:</p> <ul> <li>Acur\u00e1cia: Propor\u00e7\u00e3o de previs\u00f5es corretas em rela\u00e7\u00e3o ao total de previs\u00f5es.</li> <li>Precis\u00e3o: Propor\u00e7\u00e3o de verdadeiros positivos em rela\u00e7\u00e3o ao total de positivos previstos.</li> <li>Revoca\u00e7\u00e3o: Propor\u00e7\u00e3o de verdadeiros positivos em rela\u00e7\u00e3o ao total de positivos reais.</li> <li>F1-Score: M\u00e9dia harm\u00f4nica entre precis\u00e3o e revoca\u00e7\u00e3o. Util quando h\u00e1 um desequil\u00edbrio entre classes.</li> <li>Matriz de Confus\u00e3o: Tabela que mostra o desempenho do modelo, detalhando verdadeiros positivos, falsos positivos, verdadeiros negativos e falsos negativos.</li> </ul>"},{"location":"classes/knn/main/","title":"Projeto","text":""},{"location":"classes/knn/main/#projeto-classificacao-das-casas-dos-eua-com-knn","title":"Projeto: Classifica\u00e7\u00e3o das casas dos EUA com KNN","text":""},{"location":"classes/knn/main/#1-exploracao-dos-dados-eda","title":"1. Explora\u00e7\u00e3o dos Dados (EDA)","text":"<p>Nesta etapa, foi realizada a an\u00e1lise explorat\u00f3ria do dataset AmesHousing.csv, que cont\u00e9m informa\u00e7\u00f5es sobre as casas em Ames, Iowa.</p> <p>Toda esta parte foi analisada anteriormente no arquivo processamento.py.</p> OutputCode <pre><code>Primeiras 5 linhas do dataset:\n\nage  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  ca  thal  target\n0   63    1   0       145   233    1        2      150      0      2.3      2   0     2       0\n1   67    1   3       160   286    0        2      108      1      1.5      1   3     1       1\n2   67    1   3       120   229    0        2      129      1      2.6      1   2     3       1\n3   37    1   2       130   250    0        0      187      0      3.5      2   0     1       0\n4   41    0   1       130   204    0        2      172      0      1.4      0   0     1       0\n\nInforma\u00e7\u00f5es do dataset:\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 303 entries, 0 to 302\nData columns (total 14 columns):\n#   Column    Non-Null Count  Dtype\n---  ------    --------------  -----\n0   age       303 non-null    int64\n1   sex       303 non-null    int64\n2   cp        303 non-null    int64\n3   trestbps  303 non-null    int64\n4   chol      303 non-null    int64\n5   fbs       303 non-null    int64\n6   restecg   303 non-null    int64\n7   thalach   303 non-null    int64\n8   exang     303 non-null    int64\n9   oldpeak   303 non-null    float64\n10  slope     303 non-null    int64\n11  ca        303 non-null    int64\n12  thal      303 non-null    int64\n13  target    303 non-null    int64\ndtypes: float64(1), int64(13)\nmemory usage: 33.3 KB\nNone\n\nEstat\u00edsticas descritivas:\n\nage         sex          cp    trestbps  ...       slope          ca        thal      targetcount  303.000000  303.000000  303.000000  303.000000  ...  303.000000  303.000000  303.000000  303.000000mean    54.438944    0.679868    2.158416  131.689769  ...    0.600660    0.663366    1.831683    0.458746std      9.038662    0.467299    0.960126   17.599748  ...    0.616226    0.934375    0.956705    0.499120min     29.000000    0.000000    0.000000   94.000000  ...    0.000000    0.000000    1.000000    0.00000025%     48.000000    0.000000    2.000000  120.000000  ...    0.000000    0.000000    1.000000    0.00000050%     56.000000    1.000000    2.000000  130.000000  ...    1.000000    0.000000    1.000000    0.00000075%     61.000000    1.000000    3.000000  140.000000  ...    1.000000    1.000000    3.000000    1.000000max     77.000000    1.000000    3.000000  200.000000  ...    2.000000    3.000000    3.000000    1.000000\n[8 rows x 14 columns]\n\nValores ausentes por coluna:\n\nage         0\nsex         0\ncp          0\ntrestbps    0\nchol        0\nfbs         0\nrestecg     0\nthalach     0\nexang       0\noldpeak     0\nslope       0\nca          0\nthal        0\ntarget      0\ndtype: int64\n</code></pre> <pre><code>import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndados = pd.read_csv('data/heart.csv')\n\nprint(\"Primeiras 5 linhas do dataset:\")\nprint(dados.head())\nprint(\"\\nInforma\u00e7\u00f5es do dataset:\")\nprint(dados.info())\nprint(\"\\nEstat\u00edsticas descritivas:\")\nprint(dados.describe(include='all'))\nprint(\"\\nValores ausentes por coluna:\")\nprint(dados.isnull().sum())</code></pre>"},{"location":"classes/knn/main/#2-pre-processamento","title":"2. Pr\u00e9-processamento","text":"<p>Feito anteriormente no arquivo processamento.py, o pr\u00e9-processamento incluiu:</p> <ul> <li>Tratamento de valores ausentes, como preenchimento por m\u00e9dia/mediana/moda e remo\u00e7\u00e3o de linhas/colunas.</li> <li>Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas, utilizando as t\u00e9cnicas de One-Hot Encoding e Label Encoding.</li> </ul> <p>Para o modelo KNN, selecionei as 10 features mais relevantes utilizando o m\u00e9todo <code>SelectKBest</code> com a fun\u00e7\u00e3o de pontua\u00e7\u00e3o <code>f_classif</code>. Mas por qu\u00ea eu tinha que fazer essa sele\u00e7\u00e3o? Porque o KNN \u00e9 um algoritmo baseado em dist\u00e2ncia, e muitas features irrelevantes ou redundantes podem introduzir ru\u00eddo e prejudicar o desempenho do modelo. Ao selecionar as features mais importantes, podemos melhorar a precis\u00e3o e a efici\u00eancia do KNN.</p> <p>\u00c9 importante tamb\u00e9m normalizar ou padronizar as features num\u00e9ricas para evitar que vari\u00e1veis com escalas maiores dominem a dist\u00e2ncia calculada entre os pontos. E aqui eu utilizei o <code>StandardScaler</code> para padronizar as features selecionadas. \u00c9 aconselh\u00e1vel fazer isso ap\u00f3s a sele\u00e7\u00e3o das features, para garantir que a padroniza\u00e7\u00e3o seja aplicada apenas \u00e0s vari\u00e1veis relevantes.</p> <p>A padroniza\u00e7\u00e3o \u00e9 aplicada apenas nas features, pois a var\u00edavel preditora (target) \u00e9 categ\u00f3rica e n\u00e3o deve ser alterada.</p> OutputCode <pre><code>As 10 vari\u00e1veis mais relevantes para o modelo KNN:\n['Overall Qual', 'Gr Liv Area', 'Garage Cars', 'Total Bsmt SF', '1st Flr SF', 'Full Bath', 'Year Built', 'Year Remod/Add', 'TotRms AbvGrd', 'Garage Area']\n</code></pre> <pre><code>from sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import StandardScaler\n\nselector = SelectKBest(score_func=f_classif, k=10)\nx_new = selector.fit_transform(x, y)\nselected_features = df.drop(columns=['SalePrice', 'Target']).columns[selector.get_support()]\n\nprint(\"\\nAs 10 vari\u00e1veis mais relevantes para o modelo KNN:\")\nprint(selected_features.tolist())\n\nx_scaled = StandardScaler().fit_transform(x_new)\n</code></pre>"},{"location":"classes/knn/main/#3-divisao-dos-dados","title":"3. Divis\u00e3o dos Dados","text":"<p>Com o intuito de ver se minha hip\u00f3tese \u00e9 verdadeira ou n\u00e3o, eu treinei o meu modelo dividindo os dados em conjuntos de treino e teste (70% por 30%).</p> CodeExplica\u00e7\u00e3o <pre><code># Sele\u00e7\u00e3o das features e target\nx = df[['Overall Qual', 'Year Built', 'Exter Qual', 'Bsmt Qual', 'Gr Liv Area', 'Kitchen Qual', 'Garage Cars', 'Garage Area', 'Overall Qual_scaled', 'Garage Finish_Unf']].values\ny = df['Target'].values.astype('int')\n\n# Divis\u00e3o dos dados\nX_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.3, random_state=42)</code></pre> <ul> <li> <p>As vari\u00e1veis de entrada (features -&gt; vari\u00e1veis x) e sa\u00edda (target -&gt; vari\u00e1vel y) foram definidas.</p> </li> <li> <p>Split 70/30 para treino e teste, garantindo avalia\u00e7\u00e3o justa do modelo.</p> </li> </ul>"},{"location":"classes/knn/main/#4-treinamento-do-modelo","title":"4. Treinamento do Modelo","text":"<p>Antes do treinamento, utilizei a valida\u00e7\u00e3o cruzada para encontrar o valor ideal de k (n\u00famero de vizinhos) para o KNN. Ap\u00f3s testar valores de k de 1 a 20, o melhor valor encontrado foi k=11, com uma acur\u00e1cia m\u00e9dia de aproximadamente 0.79.</p> OutputCodeExplica\u00e7\u00e3o <pre><code>Melhor k: 11\nAcur\u00e1cia m\u00e9dia com esse k: 0.791\n</code></pre> <pre><code>#testar o k ideal com valida\u00e7\u00e3o cruzada\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'n_neighbors': range(1, 21)}  # testa k de 1 a 20\n\nknn = KNeighborsClassifier()\ngrid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\ngrid.fit(x_scaled, y)\n\nprint(f\"Melhor k: {grid.best_params_['n_neighbors']}\")\nprint(f\"Acur\u00e1cia m\u00e9dia com esse k: {grid.best_score_:.3f}\")</code></pre> <pre><code>* Utilizou-se o `GridSearchCV` para encontrar o melhor valor de k, testando valores de 1 a 20 com valida\u00e7\u00e3o cruzada de 5 folds. Para cada valor de k, a acur\u00e1cia m\u00e9dia foi calculada.\n\n* O modelo foi ajustado aos dados de treino.\n</code></pre> <p>Para a confirma\u00e7\u00e3o do valor de k, constru\u00ed um gr\u00e1fico de acur\u00e1cia m\u00e9dia versus valores de k. O gr\u00e1fico mostra que a acur\u00e1cia atinge um pico em k=11, confirmando a escolha do melhor valor de k.</p> Gr\u00e1ficoOutputCodeExplica\u00e7\u00e3o <p></p> <pre><code>Melhor valor de k: 11 (Acur\u00e1cia m\u00e9dia = 0.722)\n</code></pre> <pre><code>from sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nk_values = range(1, 21)\nmean_scores = []\n\nfor k in k_values:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, x_scaled, y, cv=5, scoring='accuracy')\n    mean_scores.append(scores.mean())\n\nplt.figure(figsize=(8, 4))\nplt.plot(k_values, mean_scores, marker='o', linestyle='-')\nplt.title(\"Acur\u00e1cia m\u00e9dia (5-fold) vs N\u00famero de vizinhos (k)\")\nplt.xlabel(\"N\u00famero de vizinhos (k)\")\nplt.ylabel(\"Acur\u00e1cia m\u00e9dia\")\nplt.grid(True)\nplt.savefig('/home/mgabriel4/Documentos/GitHub/machine-learning/docs/classes/knn/img/acuracia.png')\nplt.show()\n\nbest_k = k_values[np.argmax(mean_scores)]\nprint(f\"Melhor valor de k: {best_k} (Acur\u00e1cia m\u00e9dia = {max(mean_scores):.3f})\")</code></pre> <ul> <li> <p>O gr\u00e1fico ilustra a rela\u00e7\u00e3o entre o n\u00famero de vizinhos (k) e a acur\u00e1cia m\u00e9dia obtida por valida\u00e7\u00e3o cruzada.</p> </li> <li> <p>O pico em k=11 refor\u00e7a a escolha do melhor valor de k para o modelo.</p> </li> </ul> <p>Agora, ap\u00f3s a compara\u00e7\u00e3o entre os resultados das duas t\u00e9cnicas para descobrir o valor k mais adequado, com o valor de k definido, treinei o modelo KNN com k=11 usando os dados de treino.</p> OutputCode <pre><code>Accuracy: 0.80\n</code></pre> <pre><code>knn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")</code></pre>"},{"location":"classes/knn/main/#5-avaliacao-do-modelo","title":"5. Avalia\u00e7\u00e3o do Modelo","text":"<p>O desempenho do modelo foi avaliado com m\u00e9tricas de classifica\u00e7\u00e3o e visualiza\u00e7\u00e3o da matriz de confus\u00e3o.</p> OutputCodeGr\u00e1ficoExplica\u00e7\u00e3o <pre><code>Acur\u00e1cia: 0.8043230944254836\n\nRelat\u00f3rio de classifica\u00e7\u00e3o:\n            precision    recall  f1-score   support\n\n        0       0.80      0.81      0.81       286\n        1       0.68      0.70      0.69       274\n        2       0.92      0.88      0.90       319\n\n    accuracy                           0.80       879\nmacro avg       0.80      0.80      0.80       879\nweighted avg       0.81      0.80      0.81       879\n</code></pre> <pre><code>print(\"Acur\u00e1cia:\", accuracy_score(y_test, predictions))\nprint(\"\\nRelat\u00f3rio de classifica\u00e7\u00e3o:\\n\", classification_report(y_test, predictions))\n\ncm = confusion_matrix(y_test, predictions)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Blues')\nplt.title('Matriz de Confus\u00e3o')\nplt.show()</code></pre> <p></p> <ul> <li> <p>O modelo foi avaliado por m\u00e9tricas como precis\u00e3o, recall e F1-score.</p> </li> <li> <p>A matriz de confus\u00e3o foi visualizada para interpreta\u00e7\u00e3o dos resultados.</p> </li> </ul> <p>A matriz de confus\u00e3o indica que o modelo KNN apresentou boa capacidade de discriminar as classes de pre\u00e7o. As casas de categoria \u201cBaixa\u201d e \u201cAlta\u201d foram corretamente classificadas na maior parte dos casos (acima de 80% de acerto), enquanto a classe intermedi\u00e1ria (\u201cM\u00e9dia\u201d) apresentou maior n\u00famero de erros, sendo frequentemente confundida com as categorias vizinhas. Esse comportamento \u00e9 esperado, pois os im\u00f3veis de pre\u00e7o m\u00e9dio compartilham caracter\u00edsticas tanto de casas baratas quanto de casas de alto padr\u00e3o. No geral, a acur\u00e1cia global do modelo foi de aproximadamente 79%, indicando um desempenho satisfat\u00f3rio na classifica\u00e7\u00e3o do pre\u00e7o dos im\u00f3veis.</p>"},{"location":"classes/knn/main/#51-grafico-do-limite-de-decisao","title":"5.1 Gr\u00e1fico do Limite de Decis\u00e3o","text":"<p>O gr\u00e1fico abaixo representa o limite de decis\u00e3o do modelo KNN treinado com k=11. As regi\u00f5es coloridas indicam a classifica\u00e7\u00e3o prevista pelo modelo para diferentes combina\u00e7\u00f5es das duas features selecionadas: 'Overall Qual' (qualidade geral) e 'Gr Liv Area' (\u00e1rea de estar acima do solo). Os pontos pretos representam os dados de teste, onde cada ponto \u00e9 uma casa com sua respectiva classifica\u00e7\u00e3o real.</p> <p></p> CodeExplica\u00e7\u00e3o <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Seleciona duas features para visualiza\u00e7\u00e3o\nfeature1 = 0  # \u00cdndice da primeira feature (Overall Qual)\nfeature2 = 1  # \u00cdndice da segunda feature (Gr Liv Area)\n\nx_min, x_max = x_scaled[:, feature1].min() - 1, x_scaled[:, feature1].max() + 1\ny_min, y_max = x_scaled[:, feature2].min() - 1, x_scaled[:, feature2].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n                     np.arange(y_min, y_max, 0.01))\n\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.figure(figsize=(10, 6))\nplt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlBu)\nplt.scatter(X_test[:, feature1], X_test[:, feature2], c=y_test, edgecolor='k', marker='o', s=100, cmap=plt.cm.RdYlBu)\nplt.xlabel('Overall Qual (padronizado)')\nplt.ylabel('Gr Liv Area (padronizado)')\nplt.title('Limite de Decis\u00e3o do KNN (k=11)')\nplt.show()</code></pre> <ul> <li> <p>O gr\u00e1fico ilustra como o modelo KNN classifica diferentes regi\u00f5es do espa\u00e7o de features.</p> </li> <li> <p>As \u00e1reas coloridas representam as previs\u00f5es do modelo, enquanto os pontos pretos indicam os dados de teste reais.</p> </li> <li> <p>Podemos utilizar apenas duas features para visualizar o limite de decis\u00e3o, mas o modelo KNN foi treinado com todas as 10 features selecionadas.</p> </li> </ul>"},{"location":"classes/knn/main/#6-relatorio-final","title":"6. Relat\u00f3rio Final","text":"<p>O modelo KNN se mostrou eficiente para a tarefa de classifica\u00e7\u00e3o das casas do dataset Ames Housing, obtendo uma acur\u00e1cia global de aproximadamente 80%. Ap\u00f3s a etapa de pr\u00e9-processamento \u2014 que incluiu o tratamento de valores ausentes, codifica\u00e7\u00e3o adequada das vari\u00e1veis categ\u00f3ricas e padroniza\u00e7\u00e3o das features \u2014, foi realizada a sele\u00e7\u00e3o das 10 vari\u00e1veis mais relevantes utilizando o m\u00e9todo SelectKBest, o que contribuiu para reduzir ru\u00eddo e melhorar o desempenho do modelo.</p> <p>Por meio da valida\u00e7\u00e3o cruzada com GridSearchCV, identificou-se que o melhor n\u00famero de vizinhos foi k = 11, ponto em que a acur\u00e1cia m\u00e9dia atingiu o seu valor m\u00e1ximo. A matriz de confus\u00e3o indicou que o modelo apresentou excelente desempenho nas classes \u201cBaixa\u201d e \u201cAlta\u201d, com taxas de acerto acima de 80%, e um desempenho moderado na classe \u201cM\u00e9dia\u201d, que tende naturalmente a se confundir com as faixas adjacentes de pre\u00e7o.</p> <p>A an\u00e1lise gr\u00e1fica do limite de decis\u00e3o demonstrou que o KNN foi capaz de delimitar regi\u00f5es claras de decis\u00e3o no espa\u00e7o de atributos, especialmente entre as classes extremas, refletindo a coer\u00eancia dos padr\u00f5es de qualidade e metragem presentes no conjunto de dados.</p> <p>Em suma, o modelo apresentou bom equil\u00edbrio entre simplicidade e desempenho, sendo capaz de generalizar adequadamente os padr\u00f5es do conjunto de dados. Entretanto, poss\u00edveis melhorias poderiam envolver o uso de pondera\u00e7\u00e3o de dist\u00e2ncia (weights='distance'), m\u00e9todos de redu\u00e7\u00e3o de dimensionalidade (PCA) ou at\u00e9 mesmo o ajuste de par\u00e2metros adicionais para explorar ainda mais o potencial do KNN no contexto do mercado imobili\u00e1rio.</p>"},{"location":"classes/metricas/comparacao/","title":"Compara\u00e7\u00e3o entre KNN e K-Means","text":""},{"location":"classes/metricas/comparacao/#comparacao-entre-modelos","title":"Compara\u00e7\u00e3o entre modelos","text":"Modelo Dataset / Target Tipo de problema M\u00e9tricas usadas (no texto/c\u00f3digo) N\u00fameros registrados na doc \u00c1rvore de Decis\u00e3o Ames Housing \u2192 classes de pre\u00e7o: baixa, m\u00e9dia, alta ([mgabriel4.github.io][1]) Classifica\u00e7\u00e3o (3 classes) Matriz de confus\u00e3o, an\u00e1lise de erros entre classes Nenhum valor num\u00e9rico expl\u00edcito (sem acur\u00e1cia/F1 na p\u00e1gina) KNN Ames Housing \u2192 mesmas 3 classes de pre\u00e7o ([mgabriel4.github.io][2]) Classifica\u00e7\u00e3o (3 classes) Acur\u00e1cia (treino/teste e cross-val), precision, recall, F1, matriz de confus\u00e3o CV: acc \u2248 0,79; teste: acc \u2248 0,80; F1 macro \u2248 0,80 K-Means Ames Housing \u2192 clusters interpretados como faixas de pre\u00e7o ([mgabriel4.github.io][3]) Clustering n\u00e3o supervisionado Inertia (Elbow curve), distribui\u00e7\u00e3o de clusters vs faixas de pre\u00e7o, an\u00e1lise qualitativa Sem acur\u00e1cia/F1; s\u00f3 contagem de Target x Cluster"},{"location":"classes/metricas/main/","title":"M\u00e9tricas de Avalia\u00e7\u00e3o","text":""},{"location":"classes/metricas/main/#metricas-de-avaliacao","title":"M\u00e9tricas de Avalia\u00e7\u00e3o","text":"<p>As m\u00e9tricas s\u00e3o divididas cada uma para um problema diferente em Machine Learning.</p>"},{"location":"classes/metricas/main/#problemas-de-classificacao","title":"Problemas de Classifica\u00e7\u00e3o","text":"<p>Como j\u00e1 vimos anteriormente, os problemas de classifica\u00e7\u00e3o s\u00e3o para prever uma categoria. As m\u00e9tricas para avaliar este tipo de problema, precisam avaliar como o modelo acerta e n\u00e3o s\u00f3 o quanto ele acerta.</p> <p>Matriz de Confus\u00e3o: \u00c9 um resumo visual de tudo que o modelo acerta e erra. \u00c9 dela que surgem outras m\u00e9tricas super importantes.</p> <ul> <li>Mostra COMO o modelo erra.</li> </ul> <p></p> <p>A partir desta matriz, podemos obter m\u00e9tricas como:</p> <ul> <li> <p>Acur\u00e1cia -&gt; percentual de previs\u00f5es corretas que o modelo faz. A acur\u00e1cia \u00e9 boa para utilizar apenas quando as classes est\u00e3o balanceadas.  (TP + TN) / (TP + FP + TN + FN)</p> </li> <li> <p>Precis\u00e3o -&gt; quantos resultados s\u00e3o verdadeiramente positivos dentro dos resultados que o modelo diz que \u00e9 positivos??  TP / (TP + TN)</p> </li> <li> <p>Recall (Sensibilidade) -&gt; dentro dos positivos reais, quantos o modelo encontrou?  TP / (TP + FN)</p> </li> <li> <p>Especificidade -&gt; entre todos os casos negativos, quantos o modelo encontrou os negativos corretamente?  TN / (TN + FP)</p> </li> <li> <p>F1-Score -&gt; \u00e9 o c\u00e1lculo entre a precis\u00e3o e o recall. \u00c9 uma m\u00e9trica que serve para equilibrar os dois lados quando nenhum dos lados podem ser sacrificados.  2 *((precis\u00e3o * recall) / (precis\u00e3o + recall))</p> </li> </ul> <p>Curva-ROC-AUC: mede a capacidade do modelo de separar as classes. \u00c9 \u00f3tima para a compara\u00e7\u00e3o de modelos.</p> <ul> <li>Se aumentamos sensibilidade, tende a pegar mais positivos. No entanto, gera mais falsos positivos --&gt; ESPECIFICIDADE CAI.</li> <li>Se aumentamos a especificidade, reduzimos falsos positivos. Mas gera o risco de perder positivos --&gt; SENSIBILIDADE CAI.</li> </ul> <p>Esse processo de trade-off \u00e9 representado na curva com os valores de sensibilidade no eixo Y e os valores de especificidade no eixo X. Logo, a ROC mostra como o recall e a especificidade muda quando se \u00e9 ajustado o limiar de decis\u00e3o do modelo.</p> <p></p> <p>O AUC quantifica o desempenho geral, sendo que AUC = 1 indica um classificador perfeito e AUC = 0,5 indica um classificador aleat\u00f3rio. Quanto maior o AUC, melhor o modelo separa as classes.</p>"},{"location":"classes/metricas/main/#resumo","title":"Resumo","text":"M\u00e9trica O que mede? Quando usar? Matriz de Confus\u00e3o Quantidade de verdadeiros/ falsos positivos/negativos. Diagn\u00f3stico detalhado do comportamento do modelo. Acur\u00e1cia Percentual total de acertos do modelo. Bases balanceadas; avalia\u00e7\u00e3o geral simples. Precis\u00e3o Entre os positivos previstos, quantos s\u00e3o realmente positivos. Quando falso positivo \u00e9 caro (ex.: diagn\u00f3stico errado). Recall (Sensibilidade) Entre os positivos reais, quantos o modelo encontrou. Quando n\u00e3o pode deixar passar casos positivos (ex.: fraudes). F1-Score M\u00e9dia harm\u00f4nica entre precis\u00e3o e recall. Classes desbalanceadas; equil\u00edbrio entre FP e FN. ROC-AUC Capacidade do modelo de separar classes variando o limiar. Compara\u00e7\u00e3o de modelos; avalia\u00e7\u00e3o geral de separa\u00e7\u00e3o."},{"location":"classes/metricas/main/#problemas-de-regressao","title":"Problemas de Regress\u00e3o","text":"<p>J\u00e1 os problemas de regress\u00e3o s\u00e3o para prever valores n\u00famericos cont\u00ednuos. Logo, precisamos saber sobre o tamanho do erro, e n\u00e3o se o modelo acertou ou errou.</p> <p>MAE (Erro M\u00e9dio Absoluto): \u00c9 quanto o modelo erra em m\u00e9dia.</p> <p>MSE (Erro M\u00e9dio Quadrado): Penaliza os grandes erros para uma melhoria na interpreta\u00e7\u00e3o, pois ele calcula a m\u00e9dia dos erros ao quadrado. Seu uso \u00e9 recomendado quando queremos forte penaliza\u00e7\u00f5es para outliers.</p> <p>RMSE (Raiz do MSE): \u00c9 a raiz quadrada do MSE, que volta a escala original da vari\u00e1vel target.</p> <p>MAPE (M\u00e9dia Absoluta da Porcentagem do Erro): Mede o erro do modelo em porcentagem.</p> <p>R\u00b2 (Coeficiente de Determina\u00e7\u00e3o): Quanto da varia\u00e7\u00e3o da vari\u00e1vel target o modelo consegue explicar. Escala de 0(modelo n\u00e3o explica nada) a 1(modelo explica 100%).</p>"},{"location":"classes/metricas/main/#resumo2","title":"Resumo.2","text":"M\u00e9trica O que mede? Quando usar? MAE (Mean Absolute Error) Erro m\u00e9dio absoluto entre previs\u00e3o e valor real. F\u00e1cil interpreta\u00e7\u00e3o; pouco sens\u00edvel a outliers. MSE (Mean Squared Error) M\u00e9dia dos erros ao quadrado. Quando deseja penalizar fortemente erros grandes. RMSE (Root Mean Squared Error) Raiz do MSE, voltando \u00e0 escala original do target. Compara\u00e7\u00e3o entre modelos; sens\u00edvel a outliers. MAPE (Mean Absolute Percentage Error) Erro percentual m\u00e9dio em rela\u00e7\u00e3o ao valor real. Quando escala do problema varia muito; interpreta\u00e7\u00e3o percentual. R\u00b2 (Coeficiente de Determina\u00e7\u00e3o) Propor\u00e7\u00e3o da vari\u00e2ncia explicada pelo modelo. Avalia\u00e7\u00e3o geral de desempenho; compara\u00e7\u00e3o com baseline."},{"location":"classes/projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"classes/quiz/conceitos/","title":"Quest\u00f5es B\u00e1sicas de Conceitos","text":"<p>1.O que representa a fronteira de decis\u00e3o em um classificador?     a) Uma linha reta em espa\u00e7os de alta dimensionalidade.     b) A curva de aprendizado do modelo.     c) O limite de clusters em K-Means.     d)O hiperplano que separa classes com m\u00e1xima margem.</p> <p>EXPLICA\u00c7\u00c3O: A fronteira de decis\u00e3o \u00e9 o limite que separa regi\u00f5es do espa\u00e7o de atributos onde o modelo classifica exemplos como pertencentes a diferentes classes. Em modelos lineares como SVM, essa fronteira \u00e9 um hiperplano. Para SVMs, o hiperplano \u00e9 posicionado de forma a maximizar a margem entre as classes.</p> <p>2.O que \u00e9 bias em modelos de ML?     a) Aumento de dimensionalidade.     b) T\u00e9cnica de ensemble learning.     c) Varia\u00e7\u00e3o aleat\u00f3ria nos dados de teste.     d)Erro devido a suposi\u00e7\u00f5es simplificadas no modelo.</p> <p>Bias \u00e9 o erro ocasionado por simplifica\u00e7\u00f5es no modelo.</p> <p>3.Qual \u00e9 a principal caracter\u00edstica da IA conexionista?     a) Representa\u00e7\u00e3o do conhecimento por regras simb\u00f3licas.     b) Foco em l\u00f3gica dedutiva.     c) Uso de redes neurais para simular conex\u00f5es sin\u00e1pticas.     d) Ignor\u00e2ncia de aprendizado por dados.</p> <p>4.Em Machine Learning, qual \u00e9 a principal diferen\u00e7a entre aprendizado supervisionado e n\u00e3o supervisionado?     a) O aprendizado supervisionado utiliza dados rotulados, enquanto o n\u00e3o supervisionado n\u00e3o requer r\u00f3tulos.     b) O aprendizado supervisionado \u00e9 usado apenas para problemas de classifica\u00e7\u00e3o.      c) O aprendizado n\u00e3o supervisionado \u00e9 mais r\u00e1pido que o supervisionado.      d) O aprendizado n\u00e3o supervisionado sempre produz resultados mais precisos.</p> <p>5.Em IA simb\u00f3lica, como o conhecimento \u00e9 manipulado?     a) Via gradientes e backpropagation.     b) Com recompensas em ambientes.     c)Atrav\u00e9s de s\u00edmbolos e regras l\u00f3gicas para infer\u00eancia.     d) Por meio de embeddings vetoriais.</p> <p>6.Qual \u00e9 a vantagem principal das \u00e1rvores de decis\u00e3o em ML?     a)Interpretabilidade e facilidade de visualiza\u00e7\u00e3o.     b) Necessidade de normaliza\u00e7\u00e3o pr\u00e9via dos dados.     c) Uso em problemas de regress\u00e3o n\u00e3o linear apenas.     d) Capacidade de lidar com dados de alta dimensionalidade sem redu\u00e7\u00e3o.</p> <p>7.Em IA simb\u00f3lica, qual estrutura \u00e9 comumente usada para representar conhecimento?     a) Fun\u00e7\u00f5es de ativa\u00e7\u00e3o sigmoidais.     b) Matrizes de convolu\u00e7\u00e3o.     c) Regras l\u00f3gicas e frames.     d) Vetores de embeddings.</p> <p>8.Em Machine Learning, o que caracteriza o aprendizado supervisionado?     a) N\u00e3o h\u00e1 necessidade de valida\u00e7\u00e3o cruzada.     b)O treinamento utiliza dados rotulados para prever sa\u00eddas.     c) O modelo aprende padr\u00f5es sem r\u00f3tulos nos dados.     d) O foco \u00e9 na clusteriza\u00e7\u00e3o de dados n\u00e3o estruturados.</p> <p>9.Como a fronteira de decis\u00e3o em \u00e1rvores de decis\u00e3o \u00e9 formada?     a) Por divis\u00f5es recursivas baseadas em crit\u00e9rios de impureza.      b) Por hiperplanos lineares apenas.     c) Via fun\u00e7\u00f5es de ativa\u00e7\u00e3o.     d) Sem considerar o espa\u00e7o de features. (X)</p> <p>Errei essa quest\u00e3o.. :(</p> <p>10.No tratamento de dados, o que \u00e9 one-hot encoding?     a) Balanceamento de classes.     b) Redu\u00e7\u00e3o de dimensionalidade.     c) Convers\u00e3o de vari\u00e1veis categ\u00f3ricas em vetores bin\u00e1rios.     d) Cria\u00e7\u00e3o de fronteiras de decis\u00e3o.</p>"},{"location":"classes/quiz/prova1/","title":"Quest\u00f5es Estudos para a Prova 1","text":""},{"location":"classes/quiz/prova1/#questoes-de-estudo","title":"Quest\u00f5es de estudo","text":"<ol> <li> <p>Em uma \u00e1rvore de decis\u00e3o, o que \u00e9 um n\u00f3 folha?</p> <p>a) Um ponto onde a \u00e1rvore se divide em dois ou mais ramos.</p> <p>b) Um ponto onde uma decis\u00e3o \u00e9 tomada com base em uma feature espec\u00edfica.</p> <p>c) Um ponto final que representa a classe ou valor previsto.</p> <p>d) Um ponto que conecta diferentes ramos da \u00e1rvore.</p> <p>Resposta correta: c) Um ponto final que representa a classe ou valor previsto.</p> </li> <li> <p>Qual \u00e9 o principal objetivo do pr\u00e9-processamento de dados em Machine Learning?</p> <p>a) Melhorar a performance do hardware.</p> <p>b) Transformar dados brutos em um formato adequado para an\u00e1lise.</p> <p>c) Aumentar o tamanho do dataset.</p> <p>d) Reduzir o n\u00famero de features.</p> <p>Resposta correta: b) Transformar dados brutos em um formato adequado para an\u00e1lise.</p> </li> <li> <p>Qual t\u00e9cnica de codifica\u00e7\u00e3o \u00e9 mais adequada para vari\u00e1veis categ\u00f3ricas nominais em um modelo KNN?</p> <p>a) Label Encoding</p> <p>b) One-Hot Encoding</p> <p>c) Normaliza\u00e7\u00e3o</p> <p>d) Padroniza\u00e7\u00e3o</p> <p>Resposta correta: b) One-Hot Encoding</p> </li> <li> <p>O que \u00e9 o Machine Learning?</p> <p>a) Uma t\u00e9cnica para programar computadores manualmente.</p> <p>b) Um m\u00e9todo para que a m\u00e1quina aprenda a partir dos dados, melhorando seu desempenho sem ser explicitamente programada.</p> <p>c) Um tipo de hardware especializado para c\u00e1lculos matem\u00e1ticos.</p> <p>d) Um software de edi\u00e7\u00e3o de imagens.</p> <p>Resposta correta: b) Um m\u00e9todo para que a m\u00e1quina aprenda a partir dos dados, melhorando seu desempenho sem ser explicitamente programada.</p> </li> <li> <p>Quais s\u00e3o as principais categorias de aprendizado em Machine Learning?</p> <p>a) Aprendizado supervisionado e n\u00e3o supervisionado.</p> <p>b) Aprendizado por refor\u00e7o e aprendizado profundo.</p> <p>c) Aprendizado simb\u00f3lico e conexionista.</p> <p>d) Aprendizado estat\u00edstico e heur\u00edstico.</p> <p>Resposta correta: a) Aprendizado supervisionado e n\u00e3o supervisionado.</p> </li> <li> <p>Em uma \u00e1rvore de decis\u00e3o, qual crit\u00e9rio \u00e9 comumente usado para escolher a melhor divis\u00e3o em um n\u00f3?</p> <p>a) Maximizar o ganho de informa\u00e7\u00e3o.</p> <p>b) Maximizar a entropia do n\u00f3.</p> <p>c) Minimizar o ganho de informa\u00e7\u00e3o.</p> <p>d) Minimizar a dist\u00e2ncia euclidiana.</p> <p>Resposta correta: a) Maximizar o ganho de informa\u00e7\u00e3o.</p> </li> <li> <p>Qual a principal caracter\u00edstica de uma \u00e1rvore de decis\u00e3o?</p> <p>a) Faz previs\u00f5es baseadas em uma sequ\u00eancia de regras de decis\u00e3o.</p> <p>b) Divide os dados em clusters baseados em centroides.</p> <p>c) Usa dist\u00e2ncia euclidiana para classificar amostras.</p> <p>d) Combina m\u00faltiplos modelos para melhorar a precis\u00e3o.</p> <p>Resposta correta: a) Faz previs\u00f5es baseadas em uma sequ\u00eancia de regras de decis\u00e3o.</p> </li> <li> <p>O que \u00e9 bias em modelos de ML?</p> <p>a) A variabilidade do modelo em rela\u00e7\u00e3o aos dados de treinamento.</p> <p>b) O erro devido a suposi\u00e7\u00f5es incorretas no modelo.</p> <p>c) A capacidade do modelo de generalizar para novos dados.</p> <p>d) A complexidade do modelo.</p> <p>Resposta correta: b) O erro devido a suposi\u00e7\u00f5es incorretas no modelo.</p> </li> </ol>"},{"location":"classes/random-forest/conceito/","title":"Conceito","text":""},{"location":"classes/random-forest/conceito/#random-forest","title":"Random Forest","text":"<p>O Random Forest \u00e9 um algoritmo de aprendizado supervisionado que combina m\u00faltiplas \u00e1rvores de decis\u00e3o para melhorar a precis\u00e3o e robustez das previs\u00f5es. Ele \u00e9 amplamente utilizado para tarefas de classifica\u00e7\u00e3o e regress\u00e3o devido \u00e0 sua capacidade de lidar com grandes conjuntos de dados e alta dimensionalidade.</p>"},{"location":"classes/random-forest/conceito/#funcionamento","title":"Funcionamento","text":"<ol> <li> <p>Constru\u00e7\u00e3o das \u00c1rvores: O Random Forest constr\u00f3i v\u00e1rias \u00e1rvores de decis\u00e3o a partir de diferentes subconjuntos aleat\u00f3rios dos dados de treinamento. Cada \u00e1rvore \u00e9 treinada em uma amostra bootstrap (amostragem com reposi\u00e7\u00e3o) dos dados.</p> </li> <li> <p>Sele\u00e7\u00e3o de Recursos: Durante a constru\u00e7\u00e3o de cada \u00e1rvore, um subconjunto aleat\u00f3rio de recursos (features) \u00e9 selecionado para determinar a melhor divis\u00e3o em cada n\u00f3. Isso ajuda a reduzir a correla\u00e7\u00e3o entre as \u00e1rvores e melhora a generaliza\u00e7\u00e3o do modelo.</p> </li> <li> <p>Agrega\u00e7\u00e3o de Resultados: Para fazer previs\u00f5es, o Random Forest agrega as previs\u00f5es de todas as \u00e1rvores individuais. Para tarefas de classifica\u00e7\u00e3o, a classe mais frequente entre as \u00e1rvores \u00e9 escolhida. Para tarefas de regress\u00e3o, a m\u00e9dia das previs\u00f5es \u00e9 calculada.</p> </li> </ol>"},{"location":"classes/random-forest/conceito/#vantagens-do-random-forest","title":"Vantagens do Random Forest \u2705","text":"<ul> <li>Alta Precis\u00e3o: Geralmente oferece melhor desempenho do que uma \u00fanica \u00e1rvore de decis\u00e3o.</li> <li>Robustez: Menos propenso ao overfitting devido \u00e0 agrega\u00e7\u00e3o de m\u00faltiplas \u00e1rvores.</li> <li>Capacidade de lidar com dados faltantes e vari\u00e1veis categ\u00f3ricas.</li> <li>Import\u00e2ncia das Features: Fornece medidas de import\u00e2ncia das features, ajudando na interpreta\u00e7\u00e3o do modelo.</li> </ul>"},{"location":"classes/random-forest/conceito/#desvantagens-do-random-forest","title":"Desvantagens do Random Forest \u274c","text":"<ul> <li>Complexidade: Mais dif\u00edcil de interpretar do que uma \u00fanica \u00e1rvore de decis\u00e3o.</li> <li>Custo Computacional: Requer mais recursos computacionais para treinamento e previs\u00e3o.</li> <li>Pode ser menos eficaz em conjuntos de dados muito pequenos.</li> </ul>"},{"location":"classes/random-forest/conceito/#metricas-de-avaliacao-do-random-forest","title":"M\u00e9tricas de Avalia\u00e7\u00e3o do Random Forest","text":"<p>As m\u00e9tricas de avalia\u00e7\u00e3o para o Random Forest incluem:</p> <ul> <li>Acur\u00e1cia: Propor\u00e7\u00e3o de previs\u00f5es corretas em rela\u00e7\u00e3o ao total de previs\u00f5es.</li> <li>Precis\u00e3o: Propor\u00e7\u00e3o de verdadeiros positivos em rela\u00e7\u00e3o ao total de positivos previstos.</li> <li>Revoca\u00e7\u00e3o (Sensibilidade): Propor\u00e7\u00e3o de verdadeiros positivos em rela\u00e7\u00e3o ao total de positivos reais.</li> <li>F1-Score: M\u00e9dia harm\u00f4nica entre precis\u00e3o e revoca\u00e7\u00e3o.</li> <li>AUC-ROC: \u00c1rea sob a curva ROC, que mede a capacidade de discrimina\u00e7\u00e3o do modelo.</li> </ul>"},{"location":"classes/random-forest/main/","title":"Projeto","text":""},{"location":"classes/random-forest/main/#projeto-random-forest","title":"Projeto Random Forest","text":"<p>Neste projeto, vamos construir um modelo de Random Forest para classificar as casas da base Ames Housing em diferentes categorias de pre\u00e7o.</p> <p>Nesta etapa, foi realizada a an\u00e1lise explorat\u00f3ria do dataset AmesHousing.csv, verificando as primeiras linhas, informa\u00e7\u00f5es gerais, estat\u00edsticas descritivas, valores ausentes e visualiza\u00e7\u00e3o de algumas vari\u00e1veis categ\u00f3ricas.</p> OutputCodeExplica\u00e7\u00e3o <pre><code>Primeiras 5 linhas do dataset:\n    Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area  ... Misc Val Mo Sold Yr Sold Sale Type Sale Condition SalePrice\n0      1  526301100           20        RL         141.0     31770  ...        0       5    2010       WD          Normal    215000\n1      2  526350040           20        RH          80.0     11622  ...        0       6    2010       WD          Normal    105000\n2      3  526351010           20        RL          81.0     14267  ...    12500       6    2010       WD          Normal    172000\n3      4  526353030           20        RL          93.0     11160  ...        0       4    2010       WD          Normal    244000\n4      5  527105010           60        RL          74.0     13830  ...        0       3    2010       WD          Normal    189900\n\n[5 rows x 82 columns]\n\nInforma\u00e7\u00f5es do dataset:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2930 entries, 0 to 2929\nData columns (total 82 columns):\n#   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n0   Order            2930 non-null   int64  \n1   PID              2930 non-null   int64  \n2   MS SubClass      2930 non-null   int64  \n3   MS Zoning        2930 non-null   object \n4   Lot Frontage     2440 non-null   float64\n5   Lot Area         2930 non-null   int64  \n6   Street           2930 non-null   object \n7   Alley            198 non-null    object \n8   Lot Shape        2930 non-null   object \n9   Land Contour     2930 non-null   object \n10  Utilities        2930 non-null   object \n11  Lot Config       2930 non-null   object \n12  Land Slope       2930 non-null   object \n13  Neighborhood     2930 non-null   object \n14  Condition 1      2930 non-null   object \n15  Condition 2      2930 non-null   object \n16  Bldg Type        2930 non-null   object \n17  House Style      2930 non-null   object \n18  Overall Qual     2930 non-null   int64  \n19  Overall Cond     2930 non-null   int64  \n20  Year Built       2930 non-null   int64  \n21  Year Remod/Add   2930 non-null   int64  \n22  Roof Style       2930 non-null   object \n23  Roof Matl        2930 non-null   object \n24  Exterior 1st     2930 non-null   object \n25  Exterior 2nd     2930 non-null   object \n26  Mas Vnr Type     1155 non-null   object \n27  Mas Vnr Area     2907 non-null   float64\n28  Exter Qual       2930 non-null   object \n29  Exter Cond       2930 non-null   object \n30  Foundation       2930 non-null   object \n31  Bsmt Qual        2850 non-null   object \n32  Bsmt Cond        2850 non-null   object \n33  Bsmt Exposure    2847 non-null   object \n34  BsmtFin Type 1   2850 non-null   object \n35  BsmtFin SF 1     2929 non-null   float64\n36  BsmtFin Type 2   2849 non-null   object \n37  BsmtFin SF 2     2929 non-null   float64\n38  Bsmt Unf SF      2929 non-null   float64\n39  Total Bsmt SF    2929 non-null   float64\n40  Heating          2930 non-null   object \n41  Heating QC       2930 non-null   object \n42  Central Air      2930 non-null   object \n43  Electrical       2929 non-null   object \n44  1st Flr SF       2930 non-null   int64  \n45  2nd Flr SF       2930 non-null   int64  \n46  Low Qual Fin SF  2930 non-null   int64  \n47  Gr Liv Area      2930 non-null   int64  \n48  Bsmt Full Bath   2928 non-null   float64\n49  Bsmt Half Bath   2928 non-null   float64\n50  Full Bath        2930 non-null   int64  \n51  Half Bath        2930 non-null   int64  \n52  Bedroom AbvGr    2930 non-null   int64  \n53  Kitchen AbvGr    2930 non-null   int64  \n54  Kitchen Qual     2930 non-null   object \n55  TotRms AbvGrd    2930 non-null   int64  \n56  Functional       2930 non-null   object \n57  Fireplaces       2930 non-null   int64  \n58  Fireplace Qu     1508 non-null   object \n59  Garage Type      2773 non-null   object \n60  Garage Yr Blt    2771 non-null   float64\n61  Garage Finish    2771 non-null   object \n62  Garage Cars      2929 non-null   float64\n63  Garage Area      2929 non-null   float64\n64  Garage Qual      2771 non-null   object \n65  Garage Cond      2771 non-null   object \n66  Paved Drive      2930 non-null   object \n67  Wood Deck SF     2930 non-null   int64  \n68  Open Porch SF    2930 non-null   int64  \n69  Enclosed Porch   2930 non-null   int64  \n70  3Ssn Porch       2930 non-null   int64  \n71  Screen Porch     2930 non-null   int64  \n72  Pool Area        2930 non-null   int64  \n73  Pool QC          13 non-null     object \n74  Fence            572 non-null    object \n75  Misc Feature     106 non-null    object \n76  Misc Val         2930 non-null   int64  \n77  Mo Sold          2930 non-null   int64  \n78  Yr Sold          2930 non-null   int64  \n79  Sale Type        2930 non-null   object \n80  Sale Condition   2930 non-null   object \n81  SalePrice        2930 non-null   int64  \ndtypes: float64(11), int64(28), object(43)\nmemory usage: 1.8+ MB\nNone\n\nEstat\u00edsticas descritivas:\n            Order           PID  MS SubClass MS Zoning  Lot Frontage  ...      Mo Sold      Yr Sold Sale Type Sale Condition      SalePrice\ncount   2930.00000  2.930000e+03  2930.000000      2930   2440.000000  ...  2930.000000  2930.000000      2930           2930    2930.000000\nunique         NaN           NaN          NaN         7           NaN  ...          NaN          NaN        10              6            NaN\ntop            NaN           NaN          NaN        RL           NaN  ...          NaN          NaN       WD          Normal            NaN\nfreq           NaN           NaN          NaN      2273           NaN  ...          NaN          NaN      2536           2413            NaN\nmean    1465.50000  7.144645e+08    57.387372       NaN     69.224590  ...     6.216041  2007.790444       NaN            NaN  180796.060068\nstd      845.96247  1.887308e+08    42.638025       NaN     23.365335  ...     2.714492     1.316613       NaN            NaN   79886.692357\nmin        1.00000  5.263011e+08    20.000000       NaN     21.000000  ...     1.000000  2006.000000       NaN            NaN   12789.000000\n25%      733.25000  5.284770e+08    20.000000       NaN     58.000000  ...     4.000000  2007.000000       NaN            NaN  129500.000000\n50%     1465.50000  5.354536e+08    50.000000       NaN     68.000000  ...     6.000000  2008.000000       NaN            NaN  160000.000000\n75%     2197.75000  9.071811e+08    70.000000       NaN     80.000000  ...     8.000000  2009.000000       NaN            NaN  213500.000000\nmax     2930.00000  1.007100e+09   190.000000       NaN    313.000000  ...    12.000000  2010.000000       NaN            NaN  755000.000000\n\n[11 rows x 82 columns]\n\nValores ausentes por coluna:\nOrder               0\nPID                 0\nMS SubClass         0\nMS Zoning           0\nLot Frontage      490\n                ... \nMo Sold             0\nYr Sold             0\nSale Type           0\nSale Condition      0\nSalePrice           0\nLength: 82, dtype: int64\n</code></pre> <pre><code>from matplotlib import patches\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n\ndf = pd.read_csv('data/AmesHousing.csv')\n\nprint(\"Primeiras 5 linhas do dataset:\")\nprint(df.head())\n\nprint(\"\\nInforma\u00e7\u00f5es do dataset:\")\nprint(df.info())\n\nprint(\"\\nEstat\u00edsticas descritivas:\")\nprint(df.describe(include='all'))\n\ncolunas = df.columns\nprint(\"\\nColunas do dataset:\")\nprint(colunas)\n\nnulos = df.isnull().sum()\nprint(\"\\nValores ausentes por coluna:\")\nprint(nulos.head(100).to_string())\n\nplt.style.use('ggplot')\n\nplt.figure(figsize=(15,10))\ndf.isnull().mean().sort_values(ascending=False).head(20).plot(kind='bar', color='salmon')\nplt.title(\"Percentual de Valores Ausentes nas 20 Vari\u00e1veis com Mais NAs\")\nplt.ylabel(\"% de valores faltantes\")\nplt.savefig('./docs/classes/arvore-de-decisao/img/valores_ausentes.png')\n\n#vari\u00e1veis categ\u00f3ricas\nplt.figure(figsize=(25, 20))\nplt.subplot(2, 2, 1)\nsns.countplot(data=df, x='MS Zoning', palette='viridis', order=df['MS Zoning'].value_counts().index)\nplt.title('Classifica\u00e7\u00e3o de Zonas Residenciais')\nplt.xticks(rotation=45)\nplt.xlabel('Zona de Zoneamento')\nplt.ylabel('Contagem')\nplt.tight_layout()\n\nplt.subplot(2, 2, 2)\ndf['Street'].value_counts().plot.pie(autopct='%1.1f%%', figsize=(6,6), colors=sns.color_palette('viridis', 5), labels=df['Street'].value_counts().index)\nplt.title('Tipo de Rua')\nplt.ylabel('')  #remove o label do eixo Y\nplt.tight_layout()\n\nplt.subplot(2, 2, 3)\ndf['Neighborhood'].value_counts().head(5).plot(kind='bar', color=sns.color_palette('viridis', 5))\nplt.title('Top 5 Vizinhan\u00e7as')\nplt.xticks(rotation=45)\nplt.xlabel('Vizinhan\u00e7a')\nplt.ylabel('Contagem')\nplt.tight_layout()\n\nplt.subplot(2, 2, 4)\nsns.countplot(data=df, x='House Style', palette='viridis', order=df['House Style'].value_counts().index)\nplt.xticks(rotation=45)\nplt.title('Estilo da Casa')\nplt.ylabel('Contagem')\nplt.tight_layout()\nplt.savefig('./docs/classes/arvore-de-decisao/img/categoricas.png')\n\n#vari\u00e1veis num\u00e9ricas\nplt.figure(figsize=(15, 10))\nplt.subplot(2, 2, 1)\nsns.histplot(df['SalePrice'], bins=30, kde=True, color='salmon')\nplt.title(\"Distribui\u00e7\u00e3o do Pre\u00e7o de Venda\")\nplt.xlabel(\"Pre\u00e7o de Venda\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.tight_layout()\n\nplt.subplot(2, 2, 2)\nsns.histplot(df['Gr Liv Area'], bins=30, kde=True, color='salmon')\nplt.title(\"Distribui\u00e7\u00e3o da \u00c1rea Acima do Solo\")\nplt.xlabel(\"\u00c1rea Acima do Solo (p\u00e9s\u00b2)\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.tight_layout()\n\nplt.subplot(2, 2, 3)\nsns.histplot(df['Year Built'], bins=30, kde=True, color='salmon')\nplt.title(\"Distribui\u00e7\u00e3o do Ano de Constru\u00e7\u00e3o\")\nplt.xlabel(\"Ano de Constru\u00e7\u00e3o\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.tight_layout()\n\nplt.subplot(2, 2, 4)\nsns.histplot(df['Total Bsmt SF'], bins=30, kde=True, color='salmon')\nplt.title(\"Distribui\u00e7\u00e3o da \u00c1rea do Por\u00e3o\")\nplt.xlabel(\"\u00c1rea do Por\u00e3o (p\u00e9s\u00b2)\")\nplt.ylabel(\"Frequ\u00eancia\")\nplt.tight_layout()\nplt.savefig('./docs/classes/arvore-de-decisao/img/dist_geral_numericas.png')\nplt.show()  \n\nplt.figure(figsize=(15, 10))\nplt.subplot(2, 1, 1)\nsns.boxplot(x='Neighborhood', y='SalePrice', palette='viridis', data=df)\nplt.title(\"Pre\u00e7o por Bairro\")\nplt.xticks(rotation=90)\n\nplt.subplot(2, 1, 2)\nsns.boxplot(x='Overall Qual', y='SalePrice', data=df, palette='viridis')\nplt.title(\"Qualidade Geral vs Pre\u00e7o de Venda\")\n\nplt.tight_layout()\nplt.savefig('./docs/classes/arvore-de-decisao/img/boxplots.png')\n\ncorr_cols = ['Lot Area', 'Gr Liv Area', 'Total Bsmt SF', 'Garage Area', '1st Flr SF',\n    '2nd Flr SF', 'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'TotRms AbvGrd',\n    'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add']\nplt.figure(figsize=(10,8))\nsns.heatmap(df[corr_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title(\"Correla\u00e7\u00e3o entre vari\u00e1veis num\u00e9ricas\")\nplt.savefig('./docs/classes/arvore-de-decisao/img/matriz_correlacao.png')</code></pre> <p>Utilizamos a biblioteca Pandas para a an\u00e1lise de dados e a biblioteca Matplotlib.pyplot para fazer os gr\u00e1ficos para uma melhor visualiza\u00e7\u00e3o dos dados.</p> <p>Logo ap\u00f3s carregarmos a base de dados:</p> <ul> <li>base = pd.read_csv('caminho/para/a/base')</li> </ul> <p>Utilizamos comandos para a an\u00e1lise explorat\u00f3ria da base:</p> <ul> <li> <p>base.head() -&gt; sem a especifica\u00e7\u00e3o de quantas linhas puxar, o head imprime as primeiras 5 linhas da sua base de dados.</p> </li> <li> <p>base.info() -&gt; mostra as colunas da base de dados e seus respectivos tipos.</p> </li> <li> <p>base.describe(include='all') -&gt; imprime as estat\u00edsticas descritivas das colunas da base de dados, como a frequ\u00eancia, a m\u00e9dia, o desvio padr\u00e3o e etc.</p> </li> <li> <p>base.isnull().sum() -&gt; soma todos os valores nulos por coluna.</p> </li> </ul> <p>Ap\u00f3s finalizar esse processo com a an\u00e1lise explorat\u00f3ria, precisamos fazer a visualiza\u00e7\u00e3o da an\u00e1lise realizada. Por isso, utilizamos os seguintes comandos:</p> <ul> <li> <p>plt.style.use('ggplot') -&gt; sendo plt a biblioteca do matplotlib, esse comando serve para escolhermos o estilo que </p> </li> <li> <p>plt.figure(figsize=(15, 10)) -&gt; cria uma nova figura para colocar os gr\u00e1ficos.</p> </li> <li> <p>plt.subplot(2, 2, 1) -&gt; este comando divide a figura em uma grade de 2 linhas por 2 colunas. O \u00faltimo par\u00e2metro \u00e9 a posi\u00e7\u00e3o do gr\u00e1fico.</p> </li> <li> <p>base['nome_coluna'].value_counts().plot.pie(autopct='%1.1f%%', figsize=(6,6)) -&gt; constr\u00f3i um gr\u00e1fico de pizza com a coluna escolhida da base. O comando autopct exibe as porcentagens em cada fatia.</p> </li> <li> <p>plt.title('T\u00edtulo') -&gt; intitula o gr\u00e1fico.</p> </li> <li> <p>plt.ylabel('') -&gt; remove o label do eixo Y, comando utilizado apenas em gr\u00e1ficos de pizza</p> </li> <li> <p>base['nome_coluna'].value_counts().head(5).plot(kind='bar') -&gt; constr\u00f3i um gr\u00e1fico de barra, e com o comando head(5) ir\u00e1 aparecer apenas os 5 mais frequentes daquela coluna.</p> </li> <li> <p>plt.xticks(rotation=45) -&gt; rotaciona o gr\u00e1fico de barra a 45\u00b0 para uma melhor visualiza\u00e7\u00e3o.</p> </li> <li> <p>plt.savefig('caminho/que/deseja/salvar') -&gt; salva a figura completa que foi iniciada l\u00e1 no in\u00edcio do c\u00f3digo no caminho que foi apontado.</p> </li> <li> <p>plt.show() -&gt; exibe a figura na tela.</p> </li> </ul>"},{"location":"classes/random-forest/main/#graficos-gerados-na-analise-exploratoria","title":"Gr\u00e1ficos gerados na an\u00e1lise explorat\u00f3ria","text":"<p>A partir deste gr\u00e1fico, podemos observar que algumas vari\u00e1veis possuem uma quantidade significativa de valores ausentes. Isso pode impactar a an\u00e1lise e o desempenho do modelo, sendo necess\u00e1rio considerar estrat\u00e9gias para lidar com esses dados faltantes, como imputa\u00e7\u00e3o ou remo\u00e7\u00e3o dessas vari\u00e1veis.</p> <p></p> <p>No gr\u00e1fico acima, podemos observar a distribui\u00e7\u00e3o das vari\u00e1veis categ\u00f3ricas selecionadas. Isso nos ajuda a entender a frequ\u00eancia de diferentes categorias dentro dessas vari\u00e1veis, o que pode ser \u00fatil para identificar padr\u00f5es ou tend\u00eancias no conjunto de dados. Um exemplo disso \u00e9 o gr\u00e1fico de pizza que mostra a predomin\u00e2ncia de um tipo espec\u00edfico de rua, indicando que a maioria das propriedades est\u00e1 localizada em ruas pavimentadas. E o gr\u00e1fico de classe de zona residencial, onde a maioria das propriedades est\u00e1 situada em zonas residenciais (RL: Residential Low Density).</p> <p></p> <p>No gr\u00e1fico acima, podemos observar a distribui\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas selecionadas. Isso nos ajuda a entender a frequ\u00eancia de diferentes valores dentro dessas vari\u00e1veis, o que pode ser \u00fatil para identificar padr\u00f5es ou tend\u00eancias no conjunto de dados. Um exemplo disso \u00e9 a distribui\u00e7\u00e3o do pre\u00e7o de venda, que apresenta uma assimetria \u00e0 direita, indicando que a maioria das propriedades tem pre\u00e7os mais baixos, com algumas propriedades de alto valor.</p> <p></p> <p>Os boxplots acima ilustram a rela\u00e7\u00e3o entre a qualidade geral das casas e o pre\u00e7o de venda. Podemos observar que, em geral, casas com melhor qualidade tendem a ter pre\u00e7os de venda mais altos. No entanto, tamb\u00e9m h\u00e1 uma varia\u00e7\u00e3o significativa nos pre\u00e7os dentro de cada categoria de qualidade, indicando que outros fatores al\u00e9m da qualidade geral tamb\u00e9m influenciam o pre\u00e7o de venda. Al\u00e9m disso, temos um boxplot sobre o pre\u00e7o de venda e o bairro onde a casa est\u00e1 localizada. Podemos observar que certos bairros, como NoRidge e NridgHt, apresentam pre\u00e7os de venda significativamente mais altos em compara\u00e7\u00e3o com outros bairros. Isso sugere que a localiza\u00e7\u00e3o \u00e9 um fator importante na determina\u00e7\u00e3o do valor das propriedades.</p> <p></p> <p>A matriz de correla\u00e7\u00e3o acima mostra a rela\u00e7\u00e3o entre v\u00e1rias vari\u00e1veis num\u00e9ricas no conjunto de dados. Podemos observar que algumas vari\u00e1veis, como \"Gr Liv Area\" (\u00e1rea de vida acima do solo) e \"Overall Qual\" (qualidade geral), t\u00eam uma correla\u00e7\u00e3o positiva forte com o pre\u00e7o de venda (\"SalePrice\"). Isso indica que casas com maior \u00e1rea de vida e melhor qualidade tendem a ter pre\u00e7os de venda mais altos. Outras vari\u00e1veis, como \"Lot Area\" (\u00e1rea do lote) e \"Garage Area\" (\u00e1rea da garagem), tamb\u00e9m mostram correla\u00e7\u00f5es positivas, mas em menor grau. Essas informa\u00e7\u00f5es podem ser \u00fateis para identificar quais caracter\u00edsticas das casas s\u00e3o mais influentes na determina\u00e7\u00e3o do pre\u00e7o de venda.</p>"},{"location":"classes/random-forest/main/#2-pre-processamento","title":"2. Pr\u00e9-processamento","text":"<p>Como primeira fase do pr\u00e9-processamento, precisamos tratar os valores ausentes. Como visto anteriormente, principalmente no gr\u00e1fico gerado, temos muitos valores nulos a serem tratados. Abaixo est\u00e3o listados a quantidade dos valores nulos em todas as vari\u00e1veis:</p> <ul> <li>Lot Frontage (490 valores nulos),</li> <li>Mas Vnr Type (1775 valores nulos),</li> <li>Mas Vnr Area (23 valores nulos),</li> <li>Bsmt Qual (80 valores nulos),</li> <li>Bsmt Cond (80 valores nulos),</li> <li>Bsmt Exposure (83 valores nulos),</li> <li>BsmtFin Type 1 (80 valores nulos),</li> <li>BsmtFin SF 1 (1 valor nulo),</li> <li>BsmtFin Type 2 (81 valores nulos),</li> <li>BsmtFin SF 2 (1 valor nulo),</li> <li>Bsmt Unf SF (1 valor nulo),</li> <li>Total Bsmt SF (1 valor nulo),</li> <li>Electrical (1 valor nulo),</li> <li>Bsmt Full Bath (2 valores nulos),</li> <li>Bsmt Half Bath (2 valores nulos),</li> <li>Fireplace Qu (1422 valores nulos),</li> <li>Garage Type (157 valores nulos),</li> <li>Garage Yr Blt (159 valores nulos),</li> <li>Garage Finish (159 valores nulos),</li> <li>Garage Cars (1 valor nulo),</li> <li>Garage Area (1 valor nulo),</li> <li>Garage Qual (159 valores nulos),</li> <li>Garage Cond (159 valores nulos),</li> <li>Pool QC (2917 valores nulos),</li> <li>Fence (2358 valores nulos),</li> <li>Misc Feature (2824 valores nulos).</li> </ul> <p>Para tratar esses valores nulos, utilizei as seguintes estrat\u00e9gias:</p> <ul> <li>Remo\u00e7\u00e3o das vari\u00e1veis com muitos valores nulos (mais de 50% dos dados ausentes): Mas Vnr Type, Fireplace Qu, Pool QC, Fence e Misc Feature.</li> <li>Preenchimento dos valores nulos em vari\u00e1veis num\u00e9ricas com a mediana da coluna.</li> <li>Preenchimento dos valores nulos em vari\u00e1veis categ\u00f3ricas com a moda da coluna.</li> </ul> CodeOutput <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\ndf = pd.read_csv('data/AmesHousing.csv')\n\n#tratamento de valores nulos\nmaiores_valores_nulos = ['Pool QC', 'Misc Feature', 'Alley', 'Fence', 'Fireplace Qu']\ndf = df.drop(columns=maiores_valores_nulos)\n\n# Preenchimento de valores nulos em vari\u00e1veis num\u00e9ricas com a mediana\nnum_cols = df.select_dtypes(include=['float64', 'int64']).columns\nfor col in num_cols:\n    df[col].fillna(df[col].median(), inplace=True)\n\n# Preenchimento de valores nulos em vari\u00e1veis categ\u00f3ricas com a moda\ncat_cols = df.select_dtypes(include=['object']).columns\nfor col in cat_cols:\n    df[col].fillna(df[col].mode()[0], inplace=True)\n\nnulos = df.isnull().sum()\nprint(\"\\nValores ausentes por coluna:\")\nprint(nulos.head(100).to_string())  # Verificando se ainda h\u00e1 valores nulos</code></pre> <pre><code>Valores ausentes por coluna:\n    Order              0\n    PID                0\n    MS SubClass        0\n    MS Zoning          0\n    Lot Frontage       0\n    Lot Area           0\n    Street             0\n    Lot Shape          0\n    Land Contour       0\n    Utilities          0\n    Lot Config         0\n    Land Slope         0\n    Neighborhood       0\n    Condition 1        0\n    Condition 2        0\n    Bldg Type          0\n    House Style        0\n    Overall Qual       0\n    Overall Cond       0\n    Year Built         0\n    Year Remod/Add     0\n    Roof Style         0\n    Roof Matl          0\n    Exterior 1st       0\n    Exterior 2nd       0\n    Mas Vnr Type       0\n    Mas Vnr Area       0\n    Exter Qual         0\n    Exter Cond         0\n    Foundation         0\n    Bsmt Qual          0\n    Bsmt Cond          0\n    Bsmt Exposure      0\n    BsmtFin Type 1     0\n    BsmtFin SF 1       0\n    BsmtFin Type 2     0\n    BsmtFin SF 2       0\n    Bsmt Unf SF        0\n    Total Bsmt SF      0\n    Heating            0\n    Heating QC         0\n    Central Air        0\n    Electrical         0\n    1st Flr SF         0\n    2nd Flr SF         0\n    Low Qual Fin SF    0\n    Gr Liv Area        0\n    Bsmt Full Bath     0\n    Bsmt Half Bath     0\n    Full Bath          0\n    Half Bath          0\n    Bedroom AbvGr      0\n    Kitchen AbvGr      0\n    Kitchen Qual       0\n    TotRms AbvGrd      0\n    Functional         0\n    Fireplaces         0\n    Garage Type        0\n    Garage Yr Blt      0\n    Garage Finish      0\n    Garage Cars        0\n    Garage Area        0\n    Garage Qual        0\n    Garage Cond        0\n    Paved Drive        0\n    Wood Deck SF       0\n    Open Porch SF      0\n    Enclosed Porch     0\n    3Ssn Porch         0\n    Screen Porch       0\n    Pool Area          0\n    Misc Val           0\n    Mo Sold            0\n    Yr Sold            0\n    Sale Type          0\n    Sale Condition     0\n    SalePrice          0\n</code></pre> <p>Ap\u00f3s tratar os valores nulos, precisamos transformar as vari\u00e1veis categ\u00f3ricas em num\u00e9ricas para que o modelo de \u00e1rvore de decis\u00e3o possa utiliz\u00e1-las. Utilizei duas t\u00e9cnicas principais para isso:</p> <p>Label Encoding -&gt; serve para vari\u00e1veis categ\u00f3ricas que possuem uma ordem ou hierarquia e que t\u00eam um n\u00famero limitado de categorias. Exemplo: Poor, Fair, Average, Good, Excellent.</p> <p>One-Hot Encoding -&gt; serve para vari\u00e1veis categ\u00f3ricas que n\u00e3o possuem uma ordem ou hierarquia e t\u00eam um n\u00famero elevado de categorias. Exemplo: Cor do carro (vermelho, azul, verde).</p> <p>Mapeamento Manual -&gt; para vari\u00e1veis ordinais espec\u00edficas, onde atribu\u00edmos valores num\u00e9ricos com base na ordem percebida.</p> <p>Na tabela abaixo est\u00e3o listadas as vari\u00e1veis que foram transformadas utilizando cada t\u00e9cnica:</p> T\u00e9cnica Vari\u00e1veis Mapeamento Manual Exter Qual, Exter Cond, Bsmt Qual, Bsmt Cond, Heating QC, Kitchen Qual, Garage Qual, Garage Cond, Bsmt Exposure, BsmtFin Type 1, BsmtFin Type 2, Functional One-Hot Encoding MS Zoning, Street, Lot Shape, Land Contour, Utilities, Lot Config, Land Slope, Neighborhood, Condition 1, Condition 2, Bldg Type, House Style, Roof Style, Roof Matl, Exterior 1st, Exterior 2nd, Mas Vnr Type, Foundation, Heating, Central Air, Electrical, Garage Type, Garage Finish, Paved Drive, Sale Type, Sale Condition <ul> <li>Vari\u00e1veis categ\u00f3ricas foram transformadas em num\u00e9ricas para uso no modelo.</li> </ul>"},{"location":"classes/random-forest/main/#passo-2-carregar-o-conjunto-de-dados","title":"Passo 2: Carregar o Conjunto de Dados","text":"<p>Carregamos o conjunto de dados Iris diretamente do reposit\u00f3rio do UCI Machine Learning Repository.</p> <pre><code>```python\n    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n    columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n    data = pd.read_csv(url, names=columns)\n```\n</code></pre>"},{"location":"classes/random-forest/main/#passo-3-pre-processamento-dos-dados","title":"Passo 3: Pr\u00e9-processamento dos Dados","text":"<p>Verificamos se h\u00e1 valores ausentes e codificamos a vari\u00e1vel alvo.</p> <pre><code>```python\n    print(data.isnull().sum())\n    data['species'] = data['species'].astype('category').cat.codes\n```\n</code></pre>"},{"location":"classes/random-forest/main/#passo-4-dividir-os-dados-em-conjuntos-de-treinamento-e-teste","title":"Passo 4: Dividir os Dados em Conjuntos de Treinamento e Teste","text":"<p>Dividimos os dados em conjuntos de treinamento e teste para avaliar o desempenho do modelo.</p> <pre><code>```python\nX = data.drop('species', axis=1)\ny = data['species']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n</code></pre>"},{"location":"classes/random-forest/main/#passo-5-construir-o-modelo-random-forest","title":"Passo 5: Construir o Modelo Random Forest","text":"<p>Criamos e treinamos o modelo Random Forest.</p> <pre><code>```python\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n```\n</code></pre>"},{"location":"classes/random-forest/main/#passo-6-avaliar-o-modelo","title":"Passo 6: Avaliar o Modelo","text":"<p>Avaliamos o desempenho do modelo usando m\u00e9tricas como matriz de confus\u00e3o e relat\u00f3rio de classifica\u00e7\u00e3o.</p> <pre><code>```python\ny_pred = rf_model.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n```\n</code></pre>"},{"location":"classes/random-forest/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O modelo de Random Forest foi capaz de classificar as esp\u00e9cies de flores com uma boa precis\u00e3o. A matriz de confus\u00e3o e o relat\u00f3rio de classifica\u00e7\u00e3o fornecem insights sobre o desempenho do modelo e suas \u00e1reas de melhoria. Com ajustes adicionais e mais dados, o modelo pode ser aprimorado ainda mais.</p>"},{"location":"classes/roteiro1/main/","title":"Main","text":""},{"location":"classes/roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"classes/roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"classes/roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p> /// caption Dashboard do MAAS ///</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"classes/roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"classes/roteiro1/main/#app","title":"App","text":""},{"location":"classes/roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"classes/roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <p>```mermaid architecture-beta     group api(cloud)[API]</p> <pre><code>service db(database)[Database] in api\nservice disk1(disk)[Storage] in api\nservice disk2(disk)[Storage] in api\nservice server(server)[Server] in api\n\ndb:L -- R:server\ndisk1:T -- B:server\ndisk2:T -- B:db\n</code></pre> <p>```</p> <p>Mermaid</p>"},{"location":"classes/roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"classes/roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"classes/roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"classes/roteiro2/main/","title":"Main","text":""},{"location":"classes/roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<p><code>mermaid classDiagram     class Conta {         - String id         # double saldo         - Cliente cliente         + sacar(double valor)         + depositar(double valor)     }     class Cliente {         - String id         - String nome         - List&lt;Conta&gt; contas     }     class PessoaFisica {         - String cpf     }     class PessoaJuridica {         - String cnpj     }     class ContaCorrente {         - double limite         + sacar(double valor)     }     class ContaPoupanca {         + sacar(double valor)     }     Conta *-- Cliente     Conta &lt;|-- ContaCorrente     Conta &lt;|-- ContaPoupanca     Cliente &lt;|-- PessoaFisica     Cliente &lt;|-- PessoaJuridica</code></p>"},{"location":"classes/roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<p><code>mermaid sequenceDiagram   autonumber   actor User   User-&gt;&gt;Auth Service: request with token   Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims   Auth Service-&gt;&gt;Auth Service: verifies permissions   critical allowed     Auth Service-&gt;&gt;Secured Resource: authorizes the request     Secured Resource-&gt;&gt;User: returns the response   option denied     Auth Service--&gt;&gt;User: unauthorized message   end</code></p>"},{"location":"classes/roteiro3/main/","title":"Main","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> </p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> <p></p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"classes/roteiro4/main/","title":"Main","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> <p></p> <p></p> <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"classes/svm/conceito/","title":"Conceito","text":""},{"location":"classes/svm/conceito/#support-vector-machine-svm","title":"Support Vector Machine (SVM)","text":"<p>Support Vector Machine (SVM) \u00e9 um algoritmo supervisionado usado para classifica\u00e7\u00e3o e regress\u00e3o, cujo objetivo principal \u00e9 encontrar o hiperplano que melhor separa os dados. Esse \u201cmelhor\u201d hiperplano \u00e9 aquele que maximiza a margem, ou seja, a dist\u00e2ncia entre o hiperplano e os pontos mais pr\u00f3ximos de cada classe \u2014 os famosos support vectors.</p>"},{"location":"classes/svm/conceito/#intuicao-do-svm","title":"Intui\u00e7\u00e3o do SVM","text":"<p>Imagine duas classes de pontos num plano 2D. Existem infinitas linhas que separam essas classes, mas apenas uma maximiza a dist\u00e2ncia at\u00e9 os pontos mais pr\u00f3ximos. Essa linha \u00e9 o hiperplano \u00f3timo.</p> <ul> <li> <p>Maior margem = melhor generaliza\u00e7\u00e3o</p> </li> <li> <p>Os \u00fanicos pontos que importam para definir o hiperplano s\u00e3o os support vectors</p> </li> <li> <p>O SVM \u00e9 robusto contra overfitting em muitos casos</p> </li> </ul>"},{"location":"classes/svm/conceito/#conceitos-fundamentais","title":"Conceitos Fundamentais","text":"<ol> <li> <p>Hiperplano: A fronteira de decis\u00e3o que separa as classes.</p> <ul> <li>Em 2D \u2192 uma linha</li> <li>Em 3D \u2192 um plano</li> <li>Em n-dimens\u00f5es \u2192 hiperplano</li> </ul> </li> <li> <p>Margem: A dist\u00e2ncia entre o hiperplano e os support vectors. O SVM busca maximizar essa margem.</p> </li> <li> <p>Support Vectors: Pontos cr\u00edticos que ficam na borda da margem. Eles s\u00e3o respons\u00e1veis por definir o hiperplano \u00f3timo.</p> </li> <li> <p>SVM Linear vs. N\u00e3o Linear</p> <ul> <li>Linear: Funciona quando os dados s\u00e3o separ\u00e1veis por uma linha (2D) ou plano (nD).</li> <li>N\u00e3o Linear: Quando os dados n\u00e3o s\u00e3o separ\u00e1veis linearmente, usamos kernels.</li> </ul> </li> </ol>"},{"location":"classes/svm/conceito/#kernel-trick","title":"Kernel Trick","text":"<p>Um dos pilares do SVM \u00e9 a kernel trick, que permite projetar dados n\u00e3o lineares em um espa\u00e7o de maior dimens\u00e3o sem precisar calcular explicitamente essa transforma\u00e7\u00e3o.</p> Kernel Quando usar Linear Dados linearmente separ\u00e1veis, muito r\u00e1pido e interpret\u00e1vel Polinomial Rela\u00e7\u00f5es n\u00e3o lineares suaves RBF (Gaussian) Kernel mais usado; captura rela\u00e7\u00f5es complexas Sigmoid Similar a redes neurais, menos comum"},{"location":"classes/svm/conceito/#parametros-importantes","title":"Par\u00e2metros Importantes","text":"<ol> <li> <p>C (Regulariza\u00e7\u00e3o): Controla o trade-off entre:</p> <ul> <li>Margem larga</li> <li>Erros aceit\u00e1veis na classifica\u00e7\u00e3o</li> <li>C alto \u2192 modelo r\u00edgido (menos margem)</li> <li>C baixo \u2192 modelo mais flex\u00edvel (margem maior)</li> </ul> </li> <li> <p>Gamma (\u03b3 \u2014 usado no kernel RBF): Define o alcance da influ\u00eancia de um ponto.</p> <ul> <li>\u03b3 alto \u2192 fronteira complexa (risco de overfitting)</li> <li>\u03b3 baixo \u2192 fronteira suave</li> </ul> </li> </ol>"},{"location":"classes/svm/conceito/#svm-para-regressao-svr","title":"SVM para Regress\u00e3o (SVR)","text":"<p>A vers\u00e3o para regress\u00e3o busca aproximar uma fun\u00e7\u00e3o dentro de um intervalo de toler\u00e2ncia \u03b5. Objetivo: encontrar uma fun\u00e7\u00e3o o mais plana poss\u00edvel, penalizando desvios acima de \u03b5.</p>"},{"location":"classes/svm/conceito/#vantagens","title":"Vantagens","text":"<ul> <li> <p>Funciona muito bem com margens claras entre classes</p> </li> <li> <p>Eficiente em alta dimensionalidade</p> </li> <li> <p>Robusto ao overfitting quando bem ajustado</p> </li> <li> <p>Kernel trick permite modelar rela\u00e7\u00f5es complexas</p> </li> </ul>"},{"location":"classes/svm/conceito/#desvantagens","title":"Desvantagens","text":"<ul> <li> <p>Pode ser muito lento em datasets grandes</p> </li> <li> <p>Alta sensibilidade \u00e0 escolha de hiperpar\u00e2metros</p> </li> <li> <p>Dif\u00edcil interpretar fronteiras n\u00e3o lineares</p> </li> <li> <p>Requer normaliza\u00e7\u00e3o dos dados</p> </li> </ul>"},{"location":"classes/svm/conceito/#quando-usar-svm","title":"Quando usar SVM?","text":"<p>Use SVM quando:</p> <ul> <li> <p>O dataset n\u00e3o \u00e9 gigantesco</p> </li> <li> <p>Voc\u00ea quer alta acur\u00e1cia</p> </li> <li> <p>H\u00e1 separabilidade clara (linear ou n\u00e3o linear)</p> </li> <li> <p>Outliers s\u00e3o controlados</p> </li> </ul> <p>Evite SVM quando:</p> <ul> <li> <p>O dataset tem milh\u00f5es de linhas</p> </li> <li> <p>Voc\u00ea precisa explicar facilmente o modelo</p> </li> </ul>"},{"location":"classes/svm/conceito/#pipeline-tipico-com-svm-em-qualquer-linguagem","title":"Pipeline t\u00edpico com SVM (em qualquer linguagem)","text":"<ol> <li> <p>Normalizar/Padronizar os dados</p> </li> <li> <p>Escolher kernel</p> </li> <li> <p>Ajustar hiperpar\u00e2metros (C, gamma, degree, etc.)</p> </li> <li> <p>Treinar o modelo</p> </li> <li> <p>Avaliar com valida\u00e7\u00e3o cruzada</p> </li> <li> <p>Interpretar (se usado kernel linear)</p> </li> </ol>"},{"location":"classes/svm/projeto/","title":"Projeto","text":""},{"location":"classes/svm/projeto/#regressao-com-support-vector-machine-svr-na-base-ameshousing","title":"Regress\u00e3o com Support Vector Machine (SVR) na base AmesHousing","text":""},{"location":"classes/svm/projeto/#1-contexto-e-objetivo","title":"1. Contexto e objetivo","text":"<p>A base AmesHousing cont\u00e9m informa\u00e7\u00f5es detalhadas sobre im\u00f3veis na cidade de Ames (EUA), com diversas vari\u00e1veis estruturais, de localiza\u00e7\u00e3o e de qualidade da constru\u00e7\u00e3o, al\u00e9m do pre\u00e7o de venda (<code>SalePrice</code>).</p> <p>O objetivo deste experimento \u00e9:</p> <p>Utilizar um modelo Support Vector Machine para regress\u00e3o (SVR) para prever o pre\u00e7o de venda dos im\u00f3veis com base nas demais vari\u00e1veis da base.</p>"},{"location":"classes/svm/projeto/#2-eda-da-base","title":"2. EDA da base","text":"<ul> <li>N\u00ba de observa\u00e7\u00f5es: 2.930 im\u00f3veis  </li> <li>N\u00ba de colunas originais: 82  </li> <li>Vari\u00e1veis incluem:</li> <li>Identificadores: <code>Order</code>, <code>PID</code></li> <li>Estruturais: <code>Overall Qual</code>, <code>Overall Cond</code>, <code>Gr Liv Area</code>, <code>Total Bsmt SF</code> etc.</li> <li>Categ\u00f3ricas: <code>MS Zoning</code>, <code>Neighborhood</code>, <code>Bldg Type</code>, <code>House Style</code> etc.</li> <li>Vari\u00e1vel alvo (target): <code>SalePrice</code> (valor de venda do im\u00f3vel, em d\u00f3lares)</li> </ul> <p>Resumo da vari\u00e1vel <code>SalePrice</code>:</p> <ul> <li>M\u00e9dia: \u2248 180.796  </li> <li>Desvio-padr\u00e3o: \u2248 79.887  </li> <li>M\u00ednimo: 12.789  </li> <li>M\u00e1ximo: 755.000  </li> </ul> <p>Isso mostra uma boa varia\u00e7\u00e3o de pre\u00e7os, com im\u00f3veis bem mais baratos e outros bem mais caros.</p>"},{"location":"classes/svm/projeto/#3-preparacao-dos-dados","title":"3. Prepara\u00e7\u00e3o dos dados","text":""},{"location":"classes/svm/projeto/#31-remocao-de-colunas-nao-informativas","title":"3.1. Remo\u00e7\u00e3o de colunas n\u00e3o informativas","text":"<p>Foram removidas as colunas:</p> <ul> <li><code>Order</code> \u2013 apenas ordem no dataset  </li> <li><code>PID</code> \u2013 identificador \u00fanico do im\u00f3vel</li> </ul> <p>Essas vari\u00e1veis n\u00e3o carregam informa\u00e7\u00e3o \u00fatil para prever o pre\u00e7o.</p>"},{"location":"classes/svm/projeto/#32-definicao-de-features-e-target","title":"3.2. Defini\u00e7\u00e3o de features e target","text":"<ul> <li>Target (<code>y</code>): <code>SalePrice</code> </li> <li>Features (<code>X</code>): todas as demais colunas, exceto <code>Order</code>, <code>PID</code> e <code>SalePrice</code>.</li> </ul>"},{"location":"classes/svm/projeto/#33-tratamento-das-variaveis","title":"3.3. Tratamento das vari\u00e1veis","text":"<p>As vari\u00e1veis categ\u00f3ricas foram transformadas em vari\u00e1veis num\u00e9ricas usando one-hot encoding:</p> <pre><code>\nX_dum = pd.get_dummies(X, drop_first=True)\n</code></pre> <p>Ap\u00f3s o one-hot:</p> <ul> <li> <p>N\u00ba de linhas: 2.930</p> </li> <li> <p>N\u00ba de colunas: 261 (incluindo todas as dummies)</p> </li> </ul> <p>Tivemos que tratar os valores ausentes, pois o SVM (SVR) n\u00e3o aceita valores NaN. Para isso, foi aplicado um SimpleImputer com estrat\u00e9gia de mediana:</p> <ul> <li>Todas as colunas num\u00e9ricas (incluindo dummies) com valores faltantes foram preenchidas com a mediana da respectiva coluna.</li> </ul> <p>Isso foi feito dentro do pipeline, para evitar data leakage.</p> <p>Padronizamos as features, pois como o SVM \u00e9 sens\u00edvel \u00e0 escala das vari\u00e1veis, as features foram padronizadas, utilizando o m\u00e9todo StandardScaler(). Cada coluna foi transformada para ter m\u00e9dia \u2248 0 e desvio-padr\u00e3o \u2248 1.</p> <p>Logo ap\u00f3s disso, como SalePrice est\u00e1 em uma escala alta, foi usada a classe TransformedTargetRegressor com StandardScaler tamb\u00e9m no alvo, para facilitar o ajuste do SVR. Assim, o modelo aprende sobre o SalePrice padronizado. As previs\u00f5es s\u00e3o, depois, transformadas de volta para o espa\u00e7o original (em d\u00f3lares).</p>"},{"location":"classes/svm/projeto/#4-divisao-treino-teste","title":"4. Divis\u00e3o treino / teste","text":"<p>Os dados foram divididos em: 70% treino e 30% teste.</p> <p>random_state = 42 para reprodutibilidade</p> <pre><code>\nX_train, X_test, y_train, y_test = train_test_split(\n    X_dum, y, test_size=0.3, random_state=42\n)</code></pre>"},{"location":"classes/svm/projeto/#5-modelagem-com-svmsvr","title":"5. Modelagem com SVM(SVR)","text":"<p>Foi utilizado um Support Vector Regressor (SVR) com kernel RBF:</p> <p>5.1. Estrutura do pipeline</p> <pre><code>pipe = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler()),\n    (\"svr\", SVR(kernel=\"rbf\", C=100.0, epsilon=0.1))\n])\n\nmodel = TransformedTargetRegressor(\n    regressor=pipe,\n    transformer=StandardScaler()\n)</code></pre> <p>Componentes:</p> <ol> <li> <p>Imputer (mediana): Trata valores ausentes em todas as colunas.</p> </li> <li> <p>StandardScaler: Padroniza as features.</p> </li> <li> <p>SVR (kernel RBF):</p> <ul> <li>kernel=\"rbf\": kernel gaussiano, captura rela\u00e7\u00f5es n\u00e3o lineares.</li> <li>C=100.0: penaliza\u00e7\u00e3o relativamente alta para erros (modelo mais \u201cr\u00edgido\u201d).</li> <li>epsilon=0.1: margem de toler\u00e2ncia em torno das previs\u00f5es no espa\u00e7o padronizado.</li> </ul> </li> <li> <p>TransformedTargetRegressor + StandardScaler: Escala o target SalePrice para facilitar o treino do SVR.</p> </li> </ol>"},{"location":"classes/svm/projeto/#52-treino-do-modelo","title":"5.2. Treino do modelo","text":"<pre><code>model.fit(X_train, y_train)</code></pre> <p>Ap\u00f3s o treino, foram feitas previs\u00f5es na base de teste:</p> <pre><code>y_pred = model.predict(X_test)</code></pre>"},{"location":"classes/svm/projeto/#6-avaliacao-do-modelo","title":"6. Avalia\u00e7\u00e3o do Modelo","text":"M\u00e9trica Valor MSE 958.564.501,73 RMSE 30.960,69 MAE 18.716,88 R\u00b2 0,8636"},{"location":"classes/svm/projeto/#interpretacao","title":"Interpreta\u00e7\u00e3o","text":"<ul> <li> <p>O R\u00b2 \u2248 0,86 indica que o modelo SVR consegue explicar cerca de 86% da varia\u00e7\u00e3o do pre\u00e7o de venda dos im\u00f3veis na base de teste.</p> </li> <li> <p>O RMSE \u2248 30,9 mil significa que, em m\u00e9dia, o erro quadr\u00e1tico m\u00e9dio em termos de desvio t\u00edpico das previs\u00f5es \u00e9 da ordem de 31 mil d\u00f3lares.</p> </li> <li> <p>O MAE \u2248 18,7 mil quer dizer que, em valor absoluto, o erro m\u00e9dio que o modelo comete por im\u00f3vel \u00e9 de cerca de 18,7 mil d\u00f3lares.</p> </li> </ul>"}]}